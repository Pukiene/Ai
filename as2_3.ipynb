{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc5422c-0e7f-4e7d-93ea-2cc07389c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Networks_classifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import f1_score as f1Score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b064965c-2733-4512-a9be-cb4c5e7ab36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:/Users/mmerk/OneDrive/Desktop/Oblivion/univero sss/ai/archive/smoking_health_data_final1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d11621c-29e6-4f70-baf7-80a2af830d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>current_smoker</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>cigs_per_day</th>\n",
       "      <th>chol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>95</td>\n",
       "      <td>110/72</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>64</td>\n",
       "      <td>121/72</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>81</td>\n",
       "      <td>127.5/76</td>\n",
       "      <td>0</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>90</td>\n",
       "      <td>122.5/80</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>62</td>\n",
       "      <td>119/80</td>\n",
       "      <td>0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>88</td>\n",
       "      <td>122.5/82.5</td>\n",
       "      <td>60</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>70</td>\n",
       "      <td>123/75</td>\n",
       "      <td>60</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>56</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>70</td>\n",
       "      <td>125/79</td>\n",
       "      <td>60</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>85</td>\n",
       "      <td>134/95</td>\n",
       "      <td>60</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>40</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>98</td>\n",
       "      <td>132/86</td>\n",
       "      <td>70</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3900 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   sex current_smoker  heart_rate blood_pressure  cigs_per_day   chol\n",
       "0      54  male            yes          95         110/72             0  219.0\n",
       "1      45  male            yes          64         121/72             0  248.0\n",
       "2      58  male            yes          81       127.5/76             0  235.0\n",
       "3      42  male            yes          90       122.5/80             0  225.0\n",
       "4      42  male            yes          62         119/80             0  226.0\n",
       "...   ...   ...            ...         ...            ...           ...    ...\n",
       "3895   37  male            yes          88     122.5/82.5            60  254.0\n",
       "3896   49  male            yes          70         123/75            60  213.0\n",
       "3897   56  male            yes          70         125/79            60  246.0\n",
       "3898   50  male            yes          85         134/95            60  340.0\n",
       "3899   40  male            yes          98         132/86            70  210.0\n",
       "\n",
       "[3900 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb673de1-58f2-4965-b398-a09e3c06342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cholesterol(value):\n",
    "    if value < 200:\n",
    "        return 1\n",
    "    elif 200 <= value < 248:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ef46a5-afe1-453d-831a-1de16bc5716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.fillna(0)\n",
    "\n",
    "if 'chol' in dataset.columns:\n",
    "   \n",
    "    dataset['chol'] = pd.to_numeric(dataset['chol'], errors='coerce')  # Convert to numeric, set invalid to NaN\n",
    "    dataset['chol'] = dataset['chol'].fillna(0) \n",
    "\n",
    "    dataset['target'] = dataset['chol'].apply(categorize_cholesterol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905881d7-f4a7-4fd8-9a15-5b2b44147fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset['target'] = dataset['chol'].apply(categorize_cholesterol)\n",
    "X = dataset.drop(['chol', 'target'], axis=1)\n",
    "Y = dataset['target'] \n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf28e8dd-356f-47c1-9723-7d407a529960",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.fillna(0)\n",
    "\n",
    "if 'blood_pressure' in dataset.columns:\n",
    "    dataset[['blood_pressure_systolic', 'blood_pressure_diastolic']] = dataset['blood_pressure'].str.split('/', expand=True)\n",
    "    dataset['blood_pressure_systolic'] = pd.to_numeric(dataset['blood_pressure_systolic'], errors='coerce').fillna(0)\n",
    "    dataset['blood_pressure_diastolic'] = pd.to_numeric(dataset['blood_pressure_diastolic'], errors='coerce').fillna(0)\n",
    "    dataset = dataset.drop(['blood_pressure'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d514c30-74db-4fe4-8d31-4d22489858d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['sex'])\n",
    "dataset = pd.get_dummies(dataset, columns=['current_smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af99cc88-79e8-402d-9eeb-772f0f85c2e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  heart_rate  cigs_per_day  blood_pressure_systolic  \\\n",
      "0   54          95             0                    110.0   \n",
      "1   45          64             0                    121.0   \n",
      "2   58          81             0                    127.5   \n",
      "3   42          90             0                    122.5   \n",
      "4   42          62             0                    119.0   \n",
      "\n",
      "   blood_pressure_diastolic  sex_female  sex_male  current_smoker_no  \\\n",
      "0                      72.0       False      True              False   \n",
      "1                      72.0       False      True              False   \n",
      "2                      76.0       False      True              False   \n",
      "3                      80.0       False      True              False   \n",
      "4                      80.0       False      True              False   \n",
      "\n",
      "   current_smoker_yes  \n",
      "0                True  \n",
      "1                True  \n",
      "2                True  \n",
      "3                True  \n",
      "4                True  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = dataset.drop(['chol', 'target'], axis=1)\n",
    "print(dataset.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71dd9e2-6eae-492e-804c-b46d99e02323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cigs_per_day</th>\n",
       "      <th>blood_pressure_systolic</th>\n",
       "      <th>blood_pressure_diastolic</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>current_smoker_no</th>\n",
       "      <th>current_smoker_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>122.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>37</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>122.5</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>123.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>125.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>50</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>134.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>132.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3900 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  heart_rate  cigs_per_day  blood_pressure_systolic  \\\n",
       "0      54          95             0                    110.0   \n",
       "1      45          64             0                    121.0   \n",
       "2      58          81             0                    127.5   \n",
       "3      42          90             0                    122.5   \n",
       "4      42          62             0                    119.0   \n",
       "...   ...         ...           ...                      ...   \n",
       "3895   37          88            60                    122.5   \n",
       "3896   49          70            60                    123.0   \n",
       "3897   56          70            60                    125.0   \n",
       "3898   50          85            60                    134.0   \n",
       "3899   40          98            70                    132.0   \n",
       "\n",
       "      blood_pressure_diastolic  sex_female  sex_male  current_smoker_no  \\\n",
       "0                         72.0           0         1                  0   \n",
       "1                         72.0           0         1                  0   \n",
       "2                         76.0           0         1                  0   \n",
       "3                         80.0           0         1                  0   \n",
       "4                         80.0           0         1                  0   \n",
       "...                        ...         ...       ...                ...   \n",
       "3895                      82.5           0         1                  0   \n",
       "3896                      75.0           0         1                  0   \n",
       "3897                      79.0           0         1                  0   \n",
       "3898                      95.0           0         1                  0   \n",
       "3899                      86.0           0         1                  0   \n",
       "\n",
       "      current_smoker_yes  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "3895                   1  \n",
       "3896                   1  \n",
       "3897                   1  \n",
       "3898                   1  \n",
       "3899                   1  \n",
       "\n",
       "[3900 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sex_female'] = dataset['sex_female'].replace({True: 1, False: 0})\n",
    "dataset['sex_male'] = dataset['sex_male'].replace({True: 1, False: 0})\n",
    "dataset['current_smoker_no'] = dataset['current_smoker_no'].replace({True: 1, False: 0})\n",
    "dataset['current_smoker_yes'] = dataset['current_smoker_yes'].replace({True: 1, False: 0})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f755aac5-428a-494a-b5b1-fc3bd0c5f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9378955-1d20-4bc2-bbe7-0a210ef29464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmScaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X = mmScaler.fit_transform(X.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb1c698b-aff8-4c6d-aeae-060bf23b8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size1 = 0.2\n",
    "random_state1 = 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size1, random_state=random_state1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c86c74c1-b92d-4a78-b32b-031ce8bf980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47aa8bb7-56a1-4c2a-9223-137e8c6d9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sklearn = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=0)\n",
    "\n",
    "mlp_sklearn.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "Y_pred = mlp_sklearn.predict(X_test)\n",
    "mlp_accuracy = accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78b55d23-10a0-41bc-a3a0-50cddbe5cbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.4756410256410256\n",
      "MLP Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.27      0.32       168\n",
      "           2       0.47      0.61      0.53       322\n",
      "           3       0.53      0.45      0.49       290\n",
      "\n",
      "    accuracy                           0.48       780\n",
      "   macro avg       0.46      0.44      0.44       780\n",
      "weighted avg       0.47      0.48      0.47       780\n",
      "\n",
      "MLP Classifier Confusion Matrix:\n",
      " [[ 45  87  36]\n",
      " [ 49 195  78]\n",
      " [ 22 137 131]]\n"
     ]
    }
   ],
   "source": [
    "mlp_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"MLP Classifier Accuracy:\", mlp_accuracy)\n",
    "print(\"MLP Classifier Classification Report:\\n\", classification_report(Y_test, Y_pred))\n",
    "print(\"MLP Classifier Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55733853-a35b-4cb3-bf22-641b07671ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.42179487 0.47179487 0.42179487 0.4025641  0.38076923]\n",
      "Average Cross-Validation Score: 0.4197435897435898\n"
     ]
    }
   ],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "cross_val_scores = cross_val_score(mlp_sklearn, X_scaled, Y, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "print(\"Average Cross-Validation Score:\", cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2dc2aa-f2ba-4d60-99da-117deb8b7795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added first Dense layer\n",
      "Added second Dense layer\n",
      "Added output Dense layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmerk\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#model = Sequential()\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Dense(64, activation='relu', input_shape=(9,)))  # Adjust input_shape for 9 features\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#odel.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "print(\"Added first Dense layer\")\n",
    "model.add(Dense(32, activation='relu'))\n",
    "print(\"Added second Dense layer\")\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"Added output Dense layer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39d33374-25fb-4053-9845-770fa1f20010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3862 - loss: 1.6749 - val_accuracy: 0.4872 - val_loss: 1.0521\n",
      "Epoch 2/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4722 - loss: 1.0360 - val_accuracy: 0.4923 - val_loss: 1.0117\n",
      "Epoch 3/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4888 - loss: 0.9961 - val_accuracy: 0.5000 - val_loss: 1.0079\n",
      "Epoch 4/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5110 - loss: 0.9613 - val_accuracy: 0.4910 - val_loss: 1.0038\n",
      "Epoch 5/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.4900 - loss: 0.9889 - val_accuracy: 0.4987 - val_loss: 1.0061\n",
      "Epoch 6/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5099 - loss: 0.9791 - val_accuracy: 0.5064 - val_loss: 1.0053\n",
      "Epoch 7/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5002 - loss: 0.9770 - val_accuracy: 0.4974 - val_loss: 1.0049\n",
      "Epoch 8/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.5010 - loss: 0.9656 - val_accuracy: 0.5013 - val_loss: 1.0036\n",
      "Epoch 9/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4884 - loss: 0.9777 - val_accuracy: 0.5038 - val_loss: 1.0032\n",
      "Epoch 10/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5021 - loss: 0.9710 - val_accuracy: 0.4923 - val_loss: 1.0085\n",
      "Epoch 11/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5194 - loss: 0.9683 - val_accuracy: 0.4962 - val_loss: 0.9992\n",
      "Epoch 12/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.4910 - loss: 0.9704 - val_accuracy: 0.4974 - val_loss: 1.0004\n",
      "Epoch 13/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.4991 - loss: 0.9649 - val_accuracy: 0.4974 - val_loss: 1.0019\n",
      "Epoch 14/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.5132 - loss: 0.9661 - val_accuracy: 0.4705 - val_loss: 1.0068\n",
      "Epoch 15/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5057 - loss: 0.9614 - val_accuracy: 0.4974 - val_loss: 1.0043\n",
      "Epoch 16/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5133 - loss: 0.9559 - val_accuracy: 0.5013 - val_loss: 1.0024\n",
      "Epoch 17/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.5009 - loss: 0.9666 - val_accuracy: 0.4974 - val_loss: 1.0122\n",
      "Epoch 18/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5154 - loss: 0.9601 - val_accuracy: 0.4923 - val_loss: 1.0017\n",
      "Epoch 19/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5139 - loss: 0.9555 - val_accuracy: 0.4821 - val_loss: 1.0115\n",
      "Epoch 20/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.5162 - loss: 0.9509 - val_accuracy: 0.4846 - val_loss: 1.0040\n",
      "Epoch 21/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5181 - loss: 0.9517 - val_accuracy: 0.4949 - val_loss: 1.0019\n",
      "Epoch 22/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.5172 - loss: 0.9621 - val_accuracy: 0.4923 - val_loss: 1.0115\n",
      "Epoch 23/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.5295 - loss: 0.9449 - val_accuracy: 0.4859 - val_loss: 1.0071\n",
      "Epoch 24/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5096 - loss: 0.9664 - val_accuracy: 0.4923 - val_loss: 1.0081\n",
      "Epoch 25/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.5248 - loss: 0.9475 - val_accuracy: 0.5038 - val_loss: 1.0042\n",
      "Epoch 26/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.5195 - loss: 0.9492 - val_accuracy: 0.4859 - val_loss: 1.0057\n",
      "Epoch 27/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4998 - loss: 0.9650 - val_accuracy: 0.4872 - val_loss: 1.0164\n",
      "Epoch 28/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.5300 - loss: 0.9504 - val_accuracy: 0.4949 - val_loss: 1.0084\n",
      "Epoch 29/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4969 - loss: 0.9658 - val_accuracy: 0.4859 - val_loss: 1.0106\n",
      "Epoch 30/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5365 - loss: 0.9455 - val_accuracy: 0.4923 - val_loss: 1.0078\n",
      "Epoch 31/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.5113 - loss: 0.9505 - val_accuracy: 0.4974 - val_loss: 1.0075\n",
      "Epoch 32/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.5242 - loss: 0.9315 - val_accuracy: 0.4782 - val_loss: 1.0106\n",
      "Epoch 33/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5170 - loss: 0.9582 - val_accuracy: 0.4897 - val_loss: 1.0207\n",
      "Epoch 34/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.5168 - loss: 0.9535 - val_accuracy: 0.4859 - val_loss: 1.0126\n",
      "Epoch 35/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5267 - loss: 0.9551 - val_accuracy: 0.4910 - val_loss: 1.0093\n",
      "Epoch 36/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5094 - loss: 0.9535 - val_accuracy: 0.4846 - val_loss: 1.0125\n",
      "Epoch 37/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5245 - loss: 0.9475 - val_accuracy: 0.4756 - val_loss: 1.0093\n",
      "Epoch 38/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.5262 - loss: 0.9432 - val_accuracy: 0.4821 - val_loss: 1.0121\n",
      "Epoch 39/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.5332 - loss: 0.9422 - val_accuracy: 0.4859 - val_loss: 1.0142\n",
      "Epoch 40/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.5182 - loss: 0.9337 - val_accuracy: 0.4846 - val_loss: 1.0160\n",
      "Epoch 41/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5276 - loss: 0.9388 - val_accuracy: 0.4859 - val_loss: 1.0079\n",
      "Epoch 42/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5372 - loss: 0.9456 - val_accuracy: 0.4769 - val_loss: 1.0138\n",
      "Epoch 43/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.5320 - loss: 0.9371 - val_accuracy: 0.4974 - val_loss: 1.0209\n",
      "Epoch 44/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5399 - loss: 0.9419 - val_accuracy: 0.4987 - val_loss: 1.0106\n",
      "Epoch 45/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5325 - loss: 0.9478 - val_accuracy: 0.4692 - val_loss: 1.0172\n",
      "Epoch 46/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5281 - loss: 0.9351 - val_accuracy: 0.4795 - val_loss: 1.0123\n",
      "Epoch 47/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5397 - loss: 0.9356 - val_accuracy: 0.4949 - val_loss: 1.0131\n",
      "Epoch 48/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5260 - loss: 0.9422 - val_accuracy: 0.4872 - val_loss: 1.0164\n",
      "Epoch 49/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.5476 - loss: 0.9244 - val_accuracy: 0.4846 - val_loss: 1.0287\n",
      "Epoch 50/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5274 - loss: 0.9304 - val_accuracy: 0.4897 - val_loss: 1.0195\n",
      "Epoch 51/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.5289 - loss: 0.9257 - val_accuracy: 0.4974 - val_loss: 1.0185\n",
      "Epoch 52/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5300 - loss: 0.9371 - val_accuracy: 0.4936 - val_loss: 1.0169\n",
      "Epoch 53/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.5294 - loss: 0.9359 - val_accuracy: 0.4782 - val_loss: 1.0257\n",
      "Epoch 54/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5368 - loss: 0.9320 - val_accuracy: 0.4974 - val_loss: 1.0215\n",
      "Epoch 55/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5593 - loss: 0.9198 - val_accuracy: 0.4718 - val_loss: 1.0223\n",
      "Epoch 56/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.5260 - loss: 0.9422 - val_accuracy: 0.4897 - val_loss: 1.0237\n",
      "Epoch 57/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.5372 - loss: 0.9362 - val_accuracy: 0.4974 - val_loss: 1.0188\n",
      "Epoch 58/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.5484 - loss: 0.9283 - val_accuracy: 0.4795 - val_loss: 1.0266\n",
      "Epoch 59/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5516 - loss: 0.9224 - val_accuracy: 0.4859 - val_loss: 1.0208\n",
      "Epoch 60/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5421 - loss: 0.9160 - val_accuracy: 0.4872 - val_loss: 1.0254\n",
      "Epoch 61/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5295 - loss: 0.9312 - val_accuracy: 0.4808 - val_loss: 1.0301\n",
      "Epoch 62/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5337 - loss: 0.9217 - val_accuracy: 0.4769 - val_loss: 1.0232\n",
      "Epoch 63/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5433 - loss: 0.9232 - val_accuracy: 0.4756 - val_loss: 1.0259\n",
      "Epoch 64/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.5430 - loss: 0.9237 - val_accuracy: 0.4769 - val_loss: 1.0220\n",
      "Epoch 65/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.5356 - loss: 0.9306 - val_accuracy: 0.4756 - val_loss: 1.0305\n",
      "Epoch 66/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.5187 - loss: 0.9288 - val_accuracy: 0.4833 - val_loss: 1.0363\n",
      "Epoch 67/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5362 - loss: 0.9229 - val_accuracy: 0.4795 - val_loss: 1.0303\n",
      "Epoch 68/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5372 - loss: 0.9143 - val_accuracy: 0.4769 - val_loss: 1.0272\n",
      "Epoch 69/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.5497 - loss: 0.9243 - val_accuracy: 0.4769 - val_loss: 1.0297\n",
      "Epoch 70/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5542 - loss: 0.9171 - val_accuracy: 0.4910 - val_loss: 1.0305\n",
      "Epoch 71/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5426 - loss: 0.9187 - val_accuracy: 0.4744 - val_loss: 1.0305\n",
      "Epoch 72/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.5416 - loss: 0.9180 - val_accuracy: 0.4872 - val_loss: 1.0308\n",
      "Epoch 73/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.5420 - loss: 0.9090 - val_accuracy: 0.4487 - val_loss: 1.0339\n",
      "Epoch 74/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5409 - loss: 0.9285 - val_accuracy: 0.4910 - val_loss: 1.0287\n",
      "Epoch 75/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.5344 - loss: 0.9179 - val_accuracy: 0.4795 - val_loss: 1.0334\n",
      "Epoch 76/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5595 - loss: 0.9091 - val_accuracy: 0.4692 - val_loss: 1.0491\n",
      "Epoch 77/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5435 - loss: 0.9259 - val_accuracy: 0.4756 - val_loss: 1.0354\n",
      "Epoch 78/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.5367 - loss: 0.9184 - val_accuracy: 0.4679 - val_loss: 1.0379\n",
      "Epoch 79/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.5744 - loss: 0.8960 - val_accuracy: 0.4769 - val_loss: 1.0325\n",
      "Epoch 80/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5482 - loss: 0.9215 - val_accuracy: 0.4795 - val_loss: 1.0329\n",
      "Epoch 81/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5414 - loss: 0.9160 - val_accuracy: 0.4833 - val_loss: 1.0333\n",
      "Epoch 82/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5469 - loss: 0.9092 - val_accuracy: 0.4718 - val_loss: 1.0336\n",
      "Epoch 83/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5330 - loss: 0.9240 - val_accuracy: 0.4654 - val_loss: 1.0491\n",
      "Epoch 84/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5660 - loss: 0.9090 - val_accuracy: 0.4577 - val_loss: 1.0398\n",
      "Epoch 85/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5485 - loss: 0.9163 - val_accuracy: 0.4910 - val_loss: 1.0428\n",
      "Epoch 86/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5656 - loss: 0.9022 - val_accuracy: 0.4769 - val_loss: 1.0364\n",
      "Epoch 87/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.5420 - loss: 0.9143 - val_accuracy: 0.4718 - val_loss: 1.0445\n",
      "Epoch 88/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5563 - loss: 0.9068 - val_accuracy: 0.4769 - val_loss: 1.0482\n",
      "Epoch 89/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5628 - loss: 0.9059 - val_accuracy: 0.4808 - val_loss: 1.0383\n",
      "Epoch 90/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.5559 - loss: 0.9071 - val_accuracy: 0.4667 - val_loss: 1.0433\n",
      "Epoch 91/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.5689 - loss: 0.8973 - val_accuracy: 0.4654 - val_loss: 1.0468\n",
      "Epoch 92/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5507 - loss: 0.9045 - val_accuracy: 0.4692 - val_loss: 1.0377\n",
      "Epoch 93/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5648 - loss: 0.9028 - val_accuracy: 0.4692 - val_loss: 1.0457\n",
      "Epoch 94/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.5536 - loss: 0.9067 - val_accuracy: 0.4628 - val_loss: 1.0585\n",
      "Epoch 95/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5649 - loss: 0.8996 - val_accuracy: 0.4615 - val_loss: 1.0473\n",
      "Epoch 96/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5518 - loss: 0.9102 - val_accuracy: 0.4654 - val_loss: 1.0465\n",
      "Epoch 97/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5592 - loss: 0.9014 - val_accuracy: 0.4487 - val_loss: 1.0467\n",
      "Epoch 98/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5692 - loss: 0.8973 - val_accuracy: 0.4603 - val_loss: 1.0433\n",
      "Epoch 99/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5429 - loss: 0.9110 - val_accuracy: 0.4718 - val_loss: 1.0448\n",
      "Epoch 100/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5655 - loss: 0.8934 - val_accuracy: 0.4538 - val_loss: 1.0640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2748a099990>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "#adam, adamw, adagrad, rmsprop, adadelta, nadam\n",
    "\n",
    "\n",
    "optimizer1 = 'adam'\n",
    "loss1 = 'sparse_categorical_crossentropy'  # For multi-class classification with integer labels\n",
    "metrics1 = ['accuracy']  # To evaluate classification performance\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer1, loss=loss1, metrics=metrics1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cddcda3-46ee-439f-97b6-911479d6cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (780, 9)\n",
      "Y_test shape: (780,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc011f47-1ec2-4de1-919a-e17847b92724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.4779 - loss: 1.0319\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "410ffe56-504b-44ea-9ae3-6cdb2a0ea5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29e4ae70-d4ce-43c9-b909-bdadaa9af160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5519 - loss: 0.9096 - val_accuracy: 0.5673 - val_loss: 0.9162\n",
      "Epoch 2/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.5462 - loss: 0.9139 - val_accuracy: 0.5689 - val_loss: 0.9146\n",
      "Epoch 3/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.5396 - loss: 0.9238 - val_accuracy: 0.5449 - val_loss: 0.9264\n",
      "Epoch 4/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.5443 - loss: 0.9079 - val_accuracy: 0.5481 - val_loss: 0.9226\n",
      "Epoch 5/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.5415 - loss: 0.9141 - val_accuracy: 0.5657 - val_loss: 0.9282\n",
      "Epoch 6/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.5675 - loss: 0.9009 - val_accuracy: 0.5337 - val_loss: 0.9368\n",
      "Epoch 7/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.5598 - loss: 0.9065 - val_accuracy: 0.5529 - val_loss: 0.9409\n",
      "Epoch 8/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.5495 - loss: 0.9009 - val_accuracy: 0.5497 - val_loss: 0.9386\n",
      "Epoch 9/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.5744 - loss: 0.8867 - val_accuracy: 0.5545 - val_loss: 0.9354\n",
      "Epoch 10/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.5609 - loss: 0.8932 - val_accuracy: 0.5529 - val_loss: 0.9378\n",
      "Epoch 11/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.5434 - loss: 0.8934 - val_accuracy: 0.5593 - val_loss: 0.9331\n",
      "Epoch 12/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.5581 - loss: 0.9059 - val_accuracy: 0.5593 - val_loss: 0.9360\n",
      "Epoch 13/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.5522 - loss: 0.8928 - val_accuracy: 0.5353 - val_loss: 0.9535\n",
      "Epoch 14/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5609 - loss: 0.8889 - val_accuracy: 0.5497 - val_loss: 0.9449\n",
      "Epoch 15/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.5540 - loss: 0.8928 - val_accuracy: 0.5465 - val_loss: 0.9581\n",
      "Epoch 16/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.5626 - loss: 0.8985 - val_accuracy: 0.5657 - val_loss: 0.9443\n",
      "Epoch 17/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.5740 - loss: 0.8765 - val_accuracy: 0.5481 - val_loss: 0.9509\n",
      "Epoch 18/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.5707 - loss: 0.8881 - val_accuracy: 0.5208 - val_loss: 0.9587\n",
      "Epoch 19/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.5643 - loss: 0.8822 - val_accuracy: 0.5369 - val_loss: 0.9551\n",
      "Epoch 20/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.5752 - loss: 0.8733 - val_accuracy: 0.5192 - val_loss: 0.9638\n",
      "Epoch 21/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.5591 - loss: 0.8888 - val_accuracy: 0.5369 - val_loss: 0.9498\n",
      "Epoch 22/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.5659 - loss: 0.8836 - val_accuracy: 0.5337 - val_loss: 0.9556\n",
      "Epoch 23/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.5508 - loss: 0.8937 - val_accuracy: 0.5288 - val_loss: 0.9614\n",
      "Epoch 24/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.5708 - loss: 0.8782 - val_accuracy: 0.5240 - val_loss: 0.9522\n",
      "Epoch 25/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.5824 - loss: 0.8812 - val_accuracy: 0.5144 - val_loss: 0.9788\n",
      "Epoch 26/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.5877 - loss: 0.8752 - val_accuracy: 0.5385 - val_loss: 0.9847\n",
      "Epoch 27/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.5749 - loss: 0.8670 - val_accuracy: 0.5240 - val_loss: 0.9577\n",
      "Epoch 28/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.5868 - loss: 0.8702 - val_accuracy: 0.5144 - val_loss: 0.9718\n",
      "Epoch 29/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.5757 - loss: 0.8690 - val_accuracy: 0.5016 - val_loss: 0.9797\n",
      "Epoch 30/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.5673 - loss: 0.8826 - val_accuracy: 0.5208 - val_loss: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2748cf61610>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2) #!!!!!!!!!!epochs=50, batch_size=32\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=30, batch_size=16, validation_split=0.2)  # Reduced epochs, smaller batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "023a644a-f440-4717-aad0-2680d13373fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.50769231 0.47948718 0.45769231 0.41666667 0.4474359 ]\n",
      "Average Cross-Validation Score: 0.46179487179487183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mlp_sklearn, X, Y, cv=5)  \n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Cross-Validation Score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83453ce2-0f04-4988-ae2b-6d80932dd7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.44871795177459717\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Neural Network Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d69371cd-9a2c-41ef-bdd6-dce41b88e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = mlp_sklearn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0512da69-ff1c-4e6e-9dac-d78af0c69a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac2c5f69-1834-4ac4-b672-3115c8960370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2 1 2 3 2 1 3 1 2 2 3 2 3 2 2 3 3 2 3 2 3 2 2 2 2 3 3 3 1 1 2 2 3 2 2\n",
      " 3 2 2 2 2 3 1 2 2 3 3 2 2 3 2 1 2 2 2 1 1 2 2 3 2 2 3 1 1 3 2 2 3 2 2 2 2\n",
      " 3 2 2 3 2 2 1 2 3 1 3 1 3 3 2 2 2 2 3 2 2 2 3 3 2 1 2 2 3 2 2 1 3 1 2 2 1\n",
      " 2 1 3 2 2 3 2 2 3 2 3 3 3 2 1 1 3 3 2 1 1 2 2 1 3 2 1 2 3 2 2 2 2 2 3 3 3\n",
      " 3 2 3 3 3 3 1 1 3 2 3 2 1 3 2 3 3 2 2 2 2 3 1 2 3 2 2 1 2 2 2 2 2 2 2 3 2\n",
      " 2 2 2 2 3 3 2 3 2 2 2 3 2 3 2 3 2 3 3 3 1 2 3 1 1 2 2 1 3 2 1 3 3 2 1 1 2\n",
      " 3 2 2 2 3 2 3 3 1 3 2 2 1 1 2 3 2 3 3 2 2 2 2 3 1 3 2 3 2 2 1 2 3 3 2 2 2\n",
      " 2 2 2 2 2 2 1 3 2 2 2 3 2 1 3 2 1 2 2 2 2 2 1 1 3 3 1 2 2 2 2 1 3 3 2 3 2\n",
      " 2 2 2 2 1 2 3 2 3 2 2 2 3 2 1 2 2 2 3 2 3 2 2 2 2 2 2 3 2 2 3 3 2 3 1 2 2\n",
      " 2 1 2 3 2 2 2 2 2 3 3 1 1 1 2 3 2 3 2 3 2 3 2 2 2 2 1 3 3 3 3 3 2 2 2 2 3\n",
      " 3 2 3 3 2 2 3 3 2 3 2 2 3 2 1 3 3 3 2 1 3 2 2 3 2 1 1 1 3 2 1 2 3 1 2 3 2\n",
      " 3 3 2 2 2 3 2 3 2 3 2 2 2 1 2 3 1 3 2 3 3 2 3 1 2 2 2 2 3 2 2 1 1 2 3 2 1\n",
      " 3 1 3 2 2 2 3 2 2 2 2 3 2 3 3 2 3 2 2 2 3 2 1 1 3 2 1 2 3 3 1 1 2 1 3 3 3\n",
      " 1 3 3 2 2 2 3 3 2 2 1 3 2 1 2 2 3 2 2 2 2 3 2 3 2 2 2 2 1 2 3 2 2 2 2 3 3\n",
      " 2 2 2 1 2 3 2 1 3 2 2 1 3 2 3 3 2 3 2 2 2 3 2 2 3 3 3 3 3 3 1 2 1 2 2 2 3\n",
      " 3 3 1 2 2 3 2 3 2 2 2 1 1 3 3 3 3 2 3 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 3\n",
      " 3 2 2 1 2 2 3 2 2 3 2 2 2 1 2 3 1 2 3 2 3 1 2 2 2 2 2 3 2 2 2 2 2 3 3 3 2\n",
      " 3 3 3 2 3 2 3 2 2 2 3 2 1 3 2 2 3 2 2 3 2 2 3 2 2 1 1 2 2 2 3 2 2 3 2 2 1\n",
      " 2 1 2 2 2 1 3 2 1 3 1 1 3 2 2 2 1 3 1 2 1 1 2 2 2 2 1 2 3 2 2 2 2 3 2 2 2\n",
      " 2 3 3 2 3 2 2 3 3 2 2 2 3 3 2 2 1 3 2 2 2 2 2 2 2 2 1 2 2 3 2 2 2 3 2 1 2\n",
      " 2 2 3 3 3 3 3 2 1 2 1 2 2 3 1 1 2 2 2 3 3 2 2 2 3 3 3 2 3 2 2 3 2 1 2 2 1\n",
      " 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3890496e-4c48-4629-a7c2-c7a430b8fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 1 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 2 actual: 3\n",
      "Y_pred: 3 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 1\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 1 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 2\n",
      "Y_pred: 2 actual: 1\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "Y_predList = []\n",
    "for i in range(len(Y_pred)):  # Iterate over the length of Y_pred, not X_test\n",
    "    print(\"Y_pred:\", Y_pred[i], \"actual:\", Y_test.iloc[i])  # Print the predictions and actual values\n",
    "    Y_predList.append(Y_pred[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fc35c85-8fc1-428a-b062-4039bbf4fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(Y_predList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c58b7292-cb09-43a6-991b-63dfdc267a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.4756410256410256\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(Y_test, predictions, average='weighted', zero_division=0)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d45c5cc-e829-42c5-acda-6723f754beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(Y_test, Y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "categories = list(report.keys())[:-3] \n",
    "\n",
    "precision = [report[str(category)]['precision'] for category in categories]  # Convert to string if needed\n",
    "recall = [report[str(category)]['recall'] for category in categories]\n",
    "#f1_score = [report[str(category)]['f1-score'] for category in categories]\n",
    "f1_score = [report[cat]['f1-score'] for cat in categories]\n",
    "\n",
    "support = [report[str(category)]['support'] for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c442a03-6648-4268-aec3-a38bfdf906f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = range(len(categories))\n",
    "width = 0.2 \n",
    "\n",
    "bar1 = ax.bar([i - width for i in x], precision, width, label='Precision')\n",
    "bar2 = ax.bar(x, recall, width, label='Recall')\n",
    "bar3 = ax.bar([i + width for i in x], f1_score, width, label='F1 Score')\n",
    "\n",
    "ax.set_xlabel('Categories')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Classification Metrics by Category')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75d65f66-68e1-4de5-8200-aed8bcd8aa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe chart shows three metrics—precision (blue), recall (orange), and F1-score (green)—for\\nthree categories (1, 2, and 3). The statement about Category 3 having \\nthe highest scores is not accurate; Category 2 has the highest recall \\n(orange bar), and its F1-score (green bar) is also relatively high. \\nhe precision for Category 3 (blue bar) appears slightly higher compared\\nto Category 2. Category 1 has noticeably lower scores across all metrics,\\nconsistent with the description. To improve the statement, clarify that\\nwhile category 3 has good precision, category 2 excels in recall and\\noverall balance (F1-score)The chart shows three metrics—precision (blue), \\nrecall (orange), and F1-score (green)—for three categories (1, 2, and 3).\\nThe statement about Category 3 having the highest scores is not accurate; \\nCategory 2 has the highest recall (orange bar), and its F1-score (green bar)\\nis also relatively high. The precision for Category 3 (blue bar) appears \\nslightly higher compared to Category 2. Category 1 has noticeably lower \\nscores across all metrics, consistent with the description. \\no improve the statement, clarify that while category 3 has good precision, \\ncategory 2 excels in recall and overall balance (F1-score) \\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The chart shows three metrics—precision (blue), recall (orange), and F1-score (green)—for\n",
    "three categories (1, 2, and 3). The statement about Category 3 having \n",
    "the highest scores is not accurate; Category 2 has the highest recall \n",
    "(orange bar), and its F1-score (green bar) is also relatively high. \n",
    "he precision for Category 3 (blue bar) appears slightly higher compared\n",
    "to Category 2. Category 1 has noticeably lower scores across all metrics,\n",
    "consistent with the description. To improve the statement, clarify that\n",
    "while category 3 has good precision, category 2 excels in recall and\n",
    "overall balance (F1-score)The chart shows three metrics—precision (blue), \n",
    "recall (orange), and F1-score (green)—for three categories (1, 2, and 3).\n",
    "The statement about Category 3 having the highest scores is not accurate; \n",
    "Category 2 has the highest recall (orange bar), and its F1-score (green bar)\n",
    "is also relatively high. The precision for Category 3 (blue bar) appears \n",
    "slightly higher compared to Category 2. Category 1 has noticeably lower \n",
    "scores across all metrics, consistent with the description. \n",
    "o improve the statement, clarify that while category 3 has good precision, \n",
    "category 2 excels in recall and overall balance (F1-score) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1877f51c-a823-4413-b863-7547f1eab60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApYAAAJOCAYAAAANn0dIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWqUlEQVR4nO3deXxM9/7H8fckkkmQhASJEPtS+9oqVfvSWHu1RXVR1ZVStbRVVelCym2VcksXFZequreldFHUVkUrltZ2qTaIVhpUEwmynt8ffubeaUabw5nMjLyefZzHw5zznXM+k3rw8T7f8x2bYRiGAAAAgKvk5+kCAAAAcG2gsQQAAIAlaCwBAABgCRpLAAAAWILGEgAAAJagsQQAAIAlaCwBAABgCRpLAAAAWILGEgAAAJagsQS83Pfff68hQ4aoevXqCgoKUunSpdW8eXNNmzZNv/32m1uvvWvXLrVv315hYWGy2WyaMWOG5dew2WyKi4uz/Lx/JSEhQTabTTabTRs2bChw3DAM1apVSzabTR06dLiia7zxxhtKSEgw9Z4NGzZctiYA8HYlPF0AgMt7++23NWzYMNWtW1fjxo1T/fr1lZOTo8TERM2dO1dbt27VsmXL3Hb9+++/X5mZmVqyZInKli2ratWqWX6NrVu3qnLlypaft7BCQkI0b968As3jxo0b9eOPPyokJOSKz/3GG2+oXLlyuu+++wr9nubNm2vr1q2qX7/+FV8XADyFxhLwUlu3btWjjz6qrl27avny5bLb7Y5jXbt21ZgxY7Rq1Sq31rB37149+OCDio2Ndds1brzxRreduzAGDBig9957T//4xz8UGhrq2D9v3jy1bt1a6enpRVJHTk6ObDabQkNDPf4zAYArxa1wwEtNmTJFNptNb731llNTeUlgYKD69OnjeJ2fn69p06bpuuuuk91uV4UKFXTvvffq+PHjTu/r0KGDGjZsqO3bt+vmm29WyZIlVaNGDb388svKz8+X9N/bxLm5uZozZ47jlrEkxcXFOX79vy6958iRI45969atU4cOHRQREaHg4GBVqVJFt912m86dO+cY4+pW+N69e9W3b1+VLVtWQUFBatq0qRYsWOA05tIt4/fff18TJkxQdHS0QkND1aVLFx08eLBwP2RJd955pyTp/fffd+xLS0vThx9+qPvvv9/le55//nm1atVK4eHhCg0NVfPmzTVv3jwZhuEYU61aNe3bt08bN250/PwuJb6Xal+4cKHGjBmjSpUqyW636/DhwwVuhZ86dUoxMTFq06aNcnJyHOffv3+/SpUqpXvuuafQnxUA3I3GEvBCeXl5WrdunVq0aKGYmJhCvefRRx/VU089pa5du2rFihV68cUXtWrVKrVp00anTp1yGpuSkqK77rpLd999t1asWKHY2FiNHz9eixYtkiT17NlTW7dulSTdfvvt2rp1q+N1YR05ckQ9e/ZUYGCg3n33Xa1atUovv/yySpUqpezs7Mu+7+DBg2rTpo327dun119/XR999JHq16+v++67T9OmTSsw/plnntHRo0f1zjvv6K233tIPP/yg3r17Ky8vr1B1hoaG6vbbb9e7777r2Pf+++/Lz89PAwYMuOxne/jhh7V06VJ99NFH6tevn0aMGKEXX3zRMWbZsmWqUaOGmjVr5vj5/XHawvjx43Xs2DHNnTtXK1euVIUKFQpcq1y5clqyZIm2b9+up556SpJ07tw53XHHHapSpYrmzp1bqM8JAEXCAOB1UlJSDEnGwIEDCzX+wIEDhiRj2LBhTvu/+eYbQ5LxzDPPOPa1b9/ekGR88803TmPr169vdO/e3WmfJGP48OFO+yZNmmS4+qNj/vz5hiQjKSnJMAzD+Pe//21IMnbv3v2ntUsyJk2a5Hg9cOBAw263G8eOHXMaFxsba5QsWdL4/fffDcMwjPXr1xuSjB49ejiNW7p0qSHJ2Lp1659e91K927dvd5xr7969hmEYxvXXX2/cd999hmEYRoMGDYz27dtf9jx5eXlGTk6O8cILLxgRERFGfn6+49jl3nvpeu3atbvssfXr1zvtnzp1qiHJWLZsmTF48GAjODjY+P777//0MwJAUSOxBK4B69evl6QCD4nccMMNqlevnr788kun/VFRUbrhhhuc9jVu3FhHjx61rKamTZsqMDBQDz30kBYsWKCffvqpUO9bt26dOnfuXCCpve+++3Tu3LkCyen/TgeQLn4OSaY+S/v27VWzZk29++672rNnj7Zv337Z2+CXauzSpYvCwsLk7++vgIAAPffcczp9+rRSU1MLfd3bbrut0GPHjRunnj176s4779SCBQs0a9YsNWrUqNDvB4CiQGMJeKFy5cqpZMmSSkpKKtT406dPS5IqVqxY4Fh0dLTj+CUREREFxtntdp0/f/4KqnWtZs2aWrt2rSpUqKDhw4erZs2aqlmzpmbOnPmn7zt9+vRlP8el4//rj5/l0nxUM5/FZrNpyJAhWrRokebOnas6dero5ptvdjn222+/Vbdu3SRdfGr/66+/1vbt2zVhwgTT13X1Of+sxvvuu08XLlxQVFQUcysBeCUaS8AL+fv7q3PnztqxY0eBh29cudRcnThxosCxX375ReXKlbOstqCgIElSVlaW0/4/zuOUpJtvvlkrV65UWlqatm3bptatW2vUqFFasmTJZc8fERFx2c8hydLP8r/uu+8+nTp1SnPnztWQIUMuO27JkiUKCAjQJ598ov79+6tNmzZq2bLlFV3T1UNQl3PixAkNHz5cTZs21enTpzV27NgruiYAuBONJeClxo8fL8Mw9OCDD7p82CUnJ0crV66UJHXq1EmSHA/fXLJ9+3YdOHBAnTt3tqyuS082f//99077L9Xiir+/v1q1aqV//OMfkqSdO3dedmznzp21bt06RyN5yT//+U+VLFnSbUvxVKpUSePGjVPv3r01ePDgy46z2WwqUaKE/P39HfvOnz+vhQsXFhhrVQqcl5enO++8UzabTZ9//rni4+M1a9YsffTRR1d9bgCwEutYAl6qdevWmjNnjoYNG6YWLVro0UcfVYMGDZSTk6Ndu3bprbfeUsOGDdW7d2/VrVtXDz30kGbNmiU/Pz/FxsbqyJEjmjhxomJiYvTEE09YVlePHj0UHh6uoUOH6oUXXlCJEiWUkJCg5ORkp3Fz587VunXr1LNnT1WpUkUXLlxwPHndpUuXy55/0qRJ+uSTT9SxY0c999xzCg8P13vvvadPP/1U06ZNU1hYmGWf5Y9efvnlvxzTs2dPTZ8+XYMGDdJDDz2k06dP65VXXnG5JFSjRo20ZMkSffDBB6pRo4aCgoKuaF7kpEmT9NVXX2n16tWKiorSmDFjtHHjRg0dOlTNmjVT9erVTZ8TANyBxhLwYg8++KBuuOEGvfbaa5o6dapSUlIUEBCgOnXqaNCgQXrsscccY+fMmaOaNWtq3rx5+sc//qGwsDDdcsstio+Pdzmn8kqFhoZq1apVGjVqlO6++26VKVNGDzzwgGJjY/XAAw84xjVt2lSrV6/WpEmTlJKSotKlS6thw4ZasWKFY46iK3Xr1tWWLVv0zDPPaPjw4Tp//rzq1aun+fPnm/oGG3fp1KmT3n33XU2dOlW9e/dWpUqV9OCDD6pChQoaOnSo09jnn39eJ06c0IMPPqizZ8+qatWqTut8FsaaNWsUHx+viRMnOiXPCQkJatasmQYMGKDNmzcrMDDQio8HAFfFZhj/s6IvAAAAcIWYYwkAAABL0FgCAADAEjSWAAAAsASNJQAAACxBYwkAAABL0FgCAADAEj69jmV+fr5++eUXhYSEmPpqNAAA4L0Mw9DZs2cVHR0tPz/vy8AuXLjg8hvRrBQYGOj4Cl1f4tON5S+//KKYmBhPlwEAANwgOTlZlStX9nQZTi5cuKDgkAgp95xbrxMVFaWkpCSfay59urEMCQmRJH216weV/v9fA97k66MnPV0CcFndakd5ugTApYyzZ9W8QQ3H3/PeJDs7W8o9J3v9wZK/m77xKi9bKfsXKDs7m8ayKF26/V06JEQhIaEergYoKLj0BU+XAFxWSCh/bsK7efU0txJBsrmpsTRs3nf7v7B8t3IAAAB4FZ9OLAEAADzCJsldiaoXB7V/hcQSAAAAliCxBAAAMMvmd3Fz17l9lO9WDgAAAK9CYgkAAGCWzebGOZa+O8mSxBIAAACWILEEAAAwizmWLvlu5QAAAPAqJJYAAABmMcfSJRJLAAAAWILEEgAAwDQ3zrH04dzPdysHAACAVyGxBAAAMIs5li6RWAIAAMASJJYAAABmsY6lS75bOQAAALwKiSUAAIBZzLF0icQSAAAAliCxBAAAMIs5li75buUAAADwKiSWAAAAZjHH0iUSSwAAAFiCxBIAAMAs5li65LuVAwAAwKuQWAIAAJhls7kxsWSOJQAAAIo5EksAAACz/GwXN3ed20eRWAIAAMASJJYAAABm8VS4S75bOQAAALwKiSUAAIBZfPOOSySWAAAAsASJJQAAgFnMsXTJdysHAACAVyGxBAAAMIs5li6RWAIAAMASNJYAAABmXZpj6a7NhE2bNql3796Kjo6WzWbT8uXLnY5nZGToscceU+XKlRUcHKx69eppzpw5TmOysrI0YsQIlStXTqVKlVKfPn10/Phx0z8WGksAAAAflpmZqSZNmmj27Nkujz/xxBNatWqVFi1apAMHDuiJJ57QiBEj9PHHHzvGjBo1SsuWLdOSJUu0efNmZWRkqFevXsrLyzNVC3MsAQAAzPKiOZaxsbGKjY297PGtW7dq8ODB6tChgyTpoYce0ptvvqnExET17dtXaWlpmjdvnhYuXKguXbpIkhYtWqSYmBitXbtW3bt3L3QtJJYAAABeKD093WnLysq6ovO0bdtWK1as0M8//yzDMLR+/XodOnTI0TDu2LFDOTk56tatm+M90dHRatiwobZs2WLqWjSWAAAAZhXBHMuYmBiFhYU5tvj4+Csq9fXXX1f9+vVVuXJlBQYG6pZbbtEbb7yhtm3bSpJSUlIUGBiosmXLOr0vMjJSKSkppq7FrXAAAAAvlJycrNDQUMdru91+Red5/fXXtW3bNq1YsUJVq1bVpk2bNGzYMFWsWNFx69sVwzBkM3lbnsYSAADArCKYYxkaGurUWF6J8+fP65lnntGyZcvUs2dPSVLjxo21e/duvfLKK+rSpYuioqKUnZ2tM2fOOKWWqampatOmjanrcSscAADgGpWTk6OcnBz5+Tm3fP7+/srPz5cktWjRQgEBAVqzZo3j+IkTJ7R3717TjSWJJQAAgGlu/K5wk7lfRkaGDh8+7HidlJSk3bt3Kzw8XFWqVFH79u01btw4BQcHq2rVqtq4caP++c9/avr06ZKksLAwDR06VGPGjFFERITCw8M1duxYNWrU6E9vlbtCYwkAAODDEhMT1bFjR8fr0aNHS5IGDx6shIQELVmyROPHj9ddd92l3377TVWrVtXkyZP1yCOPON7z2muvqUSJEurfv7/Onz+vzp07KyEhQf7+/qZqobEEAAAwy4vWsezQoYMMw7js8aioKM2fP/9PzxEUFKRZs2Zp1qxZpq79R8yxBAAAgCVILAEAAMyy2dw3x9JdSWgRILEEAACAJUgsAQAAzLK58alwtz1t7n40lgAAAGZ50cM73sR3W2IAAAB4FRJLAAAAs7gV7pLvVg4AAACvQmIJAABgFnMsXSKxBAAAgCVILAEAAMxijqVLvls5AAAAvAqJJQAAgFnMsXSJxBIAAACWILEEAAAwyWazyUZiWQCJJQAAACxBYgkAAGASiaVrJJYAAACwBIklAACAWbb/39x1bh9FYgkAAABLkFgCAACYxBxL10gsAQAAYAkSSwAAAJNILF0jsSzm5sz8u2pFltRLz45z7Hty5EOqFVnSabsttr0Hq0RxkZebq4/mvqKnbm2rR9rV1VN/u1kr3pmp/Px8x5ihraq53FYtfNODlaO4WDDvTXVq00K1Y8qpdkw59eraTl+uWeU05tDBAxo8sJ/qVCmvWpUj1LPLzTqefMxDFQNFi8SyGPt+V6I+WPiurqvfqMCxdp26aurM//5FHRAQWJSloZj6fOFcbfzoPd3/3KuqVKO2jhzYo3dfGqfg0iHqOvB+SdL0z751es+eLRuUMPkptegU64mSUcxUjK6kCXEvqVqNmpKkpe8v0pBBt2vNpm9Vt159HUn6Ubfe0kl33nOfxo5/TqFhofrh4H8UFBTk4cphNRJL12gsi6nMzAyNHna/Jr/6D/1jxtQCxwMD7SpfIcoDlaE4+3HPTjVt11VN2naSJJWLjtE3q1foyIE9jjFhERWc3rNr0xrVbdFa5StVKdJaUTx1i+3l9Hr8xBf0z3lvacf2b1S3Xn29/OIkdep6iya+EO8YU7VajaIuE/AYboUXU3FPP6EOXW7RTe07uTz+zZavdEP9qurSurGeGT1Mp0+mFnGFKI5qN2mpA4lfK+XYT5Kk5EP7dfi7RDVu08Hl+LTTJ7Xn6/W6uc+AIqwSuCgvL0/LP1yqc+cy1eKGG5Wfn6+1qz9XjVq1NbBfTzWsVVk9OrfV55987OlS4QaXEkt3bb6KxLIY+mTZv7Tv+91a9sVXLo+379RNsb3/pkqVqyj52BHNmPqC7r6th5av+Vp2u72Iq0VxEnvvozqfcVbP9u8sPz9/5efn6W+PjFWr7n1djt/y2YeylyqlFh26F3GlKM4O7NurXt3aKevCBZUqVVrvLlqqutfVU+qvKcrMyNDsGX/XUxPi9GzcFK3/crWG3jNA/165Wm3atvN06YDb0VgWM7/8fFwvPjtOCUtXyH6ZOT89b73d8es69RqoUdPmat/iOm1Y+7m697y1iCpFcfTtmpXaumq5HnxhpirVqKNjh/ZryWsvqEz5SN3U8/YC4zevXKobu9+qADvz11B0atauo7Vffau0tDR9umKZRj76gD76dK3CwsIkSbf06K2Hhz8uSWrYuIkSv9mqhfPfprG81vDNOy559Fb4pk2b1Lt3b0VHR8tms2n58uWeLKdY2PfdTp0+lapbu96kutEhqhsdom+3fKUF77yhutEhysvLK/CeCpEVFV25io789KMHKkZx8q9Z8epx76Nq1a2PKte6Tm169FPXO4fqswVvFBh7aNe3Sjn6k9pxGxxFLDAwUNVr1FLTZi00YdJLatCwkd6ZO0vhEeVUokQJ1a5bz2l87brX6efjyR6qFihaHk0sMzMz1aRJEw0ZMkS33XabJ0spNlq366jPNmx32vfUqIdVo1ZdPfzYaPn7+xd4z5nfTuvEL8dVIZKHeeBe2RfOy+bn/E91Pz8/GflGgbFfrfxAVa9rpJg69YuqPMAlwzCUnZWtwMBANW3eUj/+cMjp+I+Hf1DlGB4uu9bwVLhrHm0sY2NjFRvLEiFFqXTpENWp18BpX3DJUipbNlx16jVQZmaGXv/7ZHXveasqREbpePJRvTplksqGR6hrjz4eqhrFRZObO+vT+f9QeGQlVapRW8cO7dPq9+epbe87nMadzzirxC8/04DHJ3ioUhRXU16YqE5duqtSpcrKyMjQ8o+WasvmTVr84UpJ0qMjRuuR++/SjTe11U03t9f6tau1ZtWn+vCTNR6uHCgaPjXHMisrS1lZWY7X6enpHqzm2uTv56+DB/Zp2dLFOpv+u8pHRunGm9pr5lsLVbp0iKfLwzVu0JjntfzNV7Xo7xN19swplSkXqfZ/G6Q+Q0c6jft2zUrJMHRDN/6xg6J1KjVVIx6+X6m/nlBIaJjqN2ioxR+uVPuOXSRJPXr31dTpszXrtWma+NRo1axVR+/8c4latb7Jw5XDajab3JhYuue0RcFmGEbBe0weYLPZtGzZMt16662XHRMXF6fnn3++wP5dh1MUEhLqxuqAK7PxCMs0wXv1qFvR0yUALp1NT1edKuWVlpam0FDv+vs9PT1dYWFhCuv/lmwBJd1yDSPnnNKWPuSVn/+v+NQ6luPHj1daWppjS05mMjQAACh6NrlxHUsfjix96la43W5nHUUAAAAv5VONJQAAgDfgqXDXPNpYZmRk6PDhw47XSUlJ2r17t8LDw1WlCkszAAAA+BKPNpaJiYnq2LGj4/Xo0aMlSYMHD1ZCQoKHqgIAAPgLfPOOSx5tLDt06CAveSgdAAAAV4k5lgAAAGa5cY6l4cNzLH1quSEAAAB4LxJLAAAAk9z5VLjbnjYvAiSWAAAAsASJJQAAgEkklq6RWAIAAMASJJYAAABmsY6lSySWAAAAPmzTpk3q3bu3oqOjZbPZtHz58gJjDhw4oD59+igsLEwhISG68cYbdezYMcfxrKwsjRgxQuXKlVOpUqXUp08fHT9+3HQtNJYAAAAmXZpj6a7NjMzMTDVp0kSzZ892efzHH39U27Ztdd1112nDhg367rvvNHHiRAUFBTnGjBo1SsuWLdOSJUu0efNmZWRkqFevXsrLyzNVC7fCAQAAfFhsbKxiY2Mve3zChAnq0aOHpk2b5thXo0YNx6/T0tI0b948LVy4UF26dJEkLVq0SDExMVq7dq26d+9e6FpILAEAAEwqisQyPT3dacvKyjJdZ35+vj799FPVqVNH3bt3V4UKFdSqVSun2+U7duxQTk6OunXr5tgXHR2thg0basuWLaauR2MJAADghWJiYhQWFubY4uPjTZ8jNTVVGRkZevnll3XLLbdo9erV+tvf/qZ+/fpp48aNkqSUlBQFBgaqbNmyTu+NjIxUSkqKqetxKxwAAMCkoljHMjk5WaGhoY79drvd9Lny8/MlSX379tUTTzwhSWratKm2bNmiuXPnqn379pd9r2EYpj8jiSUAAIAXCg0NddqupLEsV66cSpQoofr16zvtr1evnuOp8KioKGVnZ+vMmTNOY1JTUxUZGWnqejSWAAAAJnnTU+F/JjAwUNdff70OHjzotP/QoUOqWrWqJKlFixYKCAjQmjVrHMdPnDihvXv3qk2bNqaux61wAAAAH5aRkaHDhw87XiclJWn37t0KDw9XlSpVNG7cOA0YMEDt2rVTx44dtWrVKq1cuVIbNmyQJIWFhWno0KEaM2aMIiIiFB4errFjx6pRo0aOp8QLi8YSAADALC/65p3ExER17NjR8Xr06NGSpMGDByshIUF/+9vfNHfuXMXHx2vkyJGqW7euPvzwQ7Vt29bxntdee00lSpRQ//79df78eXXu3FkJCQny9/c3V7phGIa58r1Henq6wsLCtOtwikJCQv/6DUAR23gk1dMlAJfVo25FT5cAuHQ2PV11qpRXWlqa08Mr3uBS7xE5ZKH8Aku65Rr52ef06/x7vPLz/xUSSwAAAJOK4qlwX8TDOwAAALAEiSUAAIBJJJaukVgCAADAEiSWAAAAJpFYukZiCQAAAEuQWAIAAJjlRetYehMSSwAAAFiCxBIAAMAk5li6RmIJAAAAS5BYAgAAmERi6RqNJQAAgEk2ubGx9OGnd7gVDgAAAEuQWAIAAJjErXDXSCwBAABgCRJLAAAAs1gg3SUSSwAAAFiCxBIAAMAk5li6RmIJAAAAS5BYAgAAmERi6RqJJQAAACxBYgkAAGCSzXZxc9e5fRWJJQAAACxBYgkAAGDSxcTSXXMs3XLaIkFiCQAAAEuQWAIAAJjlxjmWfPMOAAAAij0SSwAAAJNYx9I1EksAAABYgsQSAADAJNaxdI3EEgAAAJYgsQQAADDJz88mPz/3RIuGm85bFEgsAQAAYAkSSwAAAJOYY+kaiSUAAAAsQWIJAABgEutYukZiCQAAAEuQWAIAAJjEHEvXSCwBAABgCRJLAAAAk5hj6RqJJQAAACxBYgkAAGASiaVrJJYAAACwBIklAACASTwV7hqJJQAAACxBYgkAAGCSTW6cYynfjSxJLAEAAGAJGksAAACTLs2xdNdmxqZNm9S7d29FR0fLZrNp+fLllx378MMPy2azacaMGU77s7KyNGLECJUrV06lSpVSnz59dPz4cdM/FxpLAAAAH5aZmakmTZpo9uzZfzpu+fLl+uabbxQdHV3g2KhRo7Rs2TItWbJEmzdvVkZGhnr16qW8vDxTtTDHEgAAwCRvWscyNjZWsbGxfzrm559/1mOPPaYvvvhCPXv2dDqWlpamefPmaeHCherSpYskadGiRYqJidHatWvVvXv3QtdCYgkAAHANy8/P1z333KNx48apQYMGBY7v2LFDOTk56tatm2NfdHS0GjZsqC1btpi6FoklAACASUWxjmV6errTfrvdLrvdbvp8U6dOVYkSJTRy5EiXx1NSUhQYGKiyZcs67Y+MjFRKSoqpa5FYAgAAeKGYmBiFhYU5tvj4eNPn2LFjh2bOnKmEhATTt9gNwzD9HhJLAAAAk4pijmVycrJCQ0Md+68krfzqq6+UmpqqKlWqOPbl5eVpzJgxmjFjho4cOaKoqChlZ2frzJkzTqllamqq2rRpY+p6JJYAAABeKDQ01Gm7ksbynnvu0ffff6/du3c7tujoaI0bN05ffPGFJKlFixYKCAjQmjVrHO87ceKE9u7da7qxJLEEAAAwyZu+KzwjI0OHDx92vE5KStLu3bsVHh6uKlWqKCIiwml8QECAoqKiVLduXUlSWFiYhg4dqjFjxigiIkLh4eEaO3asGjVq5HhKvLBoLAEAAHxYYmKiOnbs6Hg9evRoSdLgwYOVkJBQqHO89tprKlGihPr376/z58+rc+fOSkhIkL+/v6laaCwBAABM8qZ1LDt06CDDMAo9/siRIwX2BQUFadasWZo1a5apa/8RcywBAABgiWsisczLN5SbX/hOHSgqwx/+u6dLAC7r/QUTPF0C4NK5jLOeLuGvuXGOpdx13iJAYgkAAABLXBOJJQAAQFHypjmW3oTEEgAAAJYgsQQAADDJm9ax9CYklgAAALAEiSUAAIBJzLF0jcQSAAAAliCxBAAAMIk5lq6RWAIAAMASJJYAAAAmMcfSNRJLAAAAWILEEgAAwCQSS9dILAEAAGAJEksAAACTeCrcNRJLAAAAWILEEgAAwCTmWLpGYwkAAGASt8Jd41Y4AAAALEFiCQAAYBK3wl0jsQQAAIAlSCwBAABMssmNcyzdc9oiQWIJAAAAS5BYAgAAmORns8nPTZGlu85bFEgsAQAAYAkSSwAAAJNYx9I1EksAAABYgsQSAADAJNaxdI3EEgAAAJYgsQQAADDJz3Zxc9e5fRWJJQAAACxBYgkAAGCWzY1zIUksAQAAUNyRWAIAAJjEOpaukVgCAADAEiSWAAAAJtn+/z93ndtXkVgCAADAEiSWAAAAJrGOpWsklgAAALAEiSUAAIBJfFe4aySWAAAAsASJJQAAgEmsY+kaiSUAAAAsQWIJAABgkp/NJj83RYvuOm9RILEEAACAJUgsAQAATGKOpWsklgAAAD5s06ZN6t27t6Kjo2Wz2bR8+XLHsZycHD311FNq1KiRSpUqpejoaN1777365ZdfnM6RlZWlESNGqFy5cipVqpT69Omj48ePm66FxhIAAMCkS+tYumszIzMzU02aNNHs2bMLHDt37px27typiRMnaufOnfroo4906NAh9enTx2ncqFGjtGzZMi1ZskSbN29WRkaGevXqpby8PFO1cCscAADAh8XGxio2NtblsbCwMK1Zs8Zp36xZs3TDDTfo2LFjqlKlitLS0jRv3jwtXLhQXbp0kSQtWrRIMTExWrt2rbp3717oWkgsAQAATLo0x9JdmzulpaXJZrOpTJkykqQdO3YoJydH3bp1c4yJjo5Ww4YNtWXLFlPnJrEEAADwQunp6U6v7Xa77Hb7VZ3zwoULevrppzVo0CCFhoZKklJSUhQYGKiyZcs6jY2MjFRKSoqp85NYAgAAmHRpHUt3bZIUExOjsLAwxxYfH39VNefk5GjgwIHKz8/XG2+88ZfjDcMwPd+zUInl66+/XugTjhw50lQBAAAAKCg5OdmRKkq6qrQyJydH/fv3V1JSktatW+d03qioKGVnZ+vMmTNOqWVqaqratGlj6jqFaixfe+21Qp3MZrPRWAIAgGue7f83d51bkkJDQ50awCt1qan84YcftH79ekVERDgdb9GihQICArRmzRr1799fknTixAnt3btX06ZNM3WtQjWWSUlJpk4KAACAopGRkaHDhw87XiclJWn37t0KDw9XdHS0br/9du3cuVOffPKJ8vLyHPMmw8PDFRgYqLCwMA0dOlRjxoxRRESEwsPDNXbsWDVq1MjxlHhhXfHDO9nZ2UpKSlLNmjVVogTPAAEAgOLjStabNHNuMxITE9WxY0fH69GjR0uSBg8erLi4OK1YsUKS1LRpU6f3rV+/Xh06dJB08e50iRIl1L9/f50/f16dO3dWQkKC/P39TdViuiM8d+6cRowYoQULFkiSDh06pBo1amjkyJGKjo7W008/bfaUAAAAuEIdOnSQYRiXPf5nxy4JCgrSrFmzNGvWrKuqxfRT4ePHj9d3332nDRs2KCgoyLG/S5cu+uCDD66qGAAAAF/gZ3Pv5qtMJ5bLly/XBx98oBtvvNEpqq1fv75+/PFHS4sDAACA7zDdWJ48eVIVKlQosD8zM9Ntcw0AAAC8iTfNsfQmpm+FX3/99fr0008dry99+LffflutW7e2rjIAAAD4FNOJZXx8vG655Rbt379fubm5mjlzpvbt26etW7dq48aN7qgRAADA6/hwsOg2phPLNm3a6Ouvv9a5c+dUs2ZNrV69WpGRkdq6datatGjhjhoBAADgA65oAcpGjRo5lhsCAAAobphj6doVNZZ5eXlatmyZDhw4IJvNpnr16qlv374slA4AAFCMme4E9+7dq759+yolJUV169aVdHGR9PLly2vFihVq1KiR5UUCAAB4E3euN+nL61ianmP5wAMPqEGDBjp+/Lh27typnTt3Kjk5WY0bN9ZDDz3kjhoBAADgA0wnlt99950SExNVtmxZx76yZctq8uTJuv766y0tDgAAwBsxx9I104ll3bp19euvvxbYn5qaqlq1allSFAAAAHxPoRLL9PR0x6+nTJmikSNHKi4uTjfeeKMkadu2bXrhhRc0depU91QJAADgRWz/v7nr3L6qUI1lmTJlnGJZwzDUv39/xz7DMCRJvXv3Vl5enhvKBAAAgLcrVGO5fv16d9cBAADgM/xsNvm5aS6ku85bFArVWLZv397ddQAAAMDHXfGK5ufOndOxY8eUnZ3ttL9x48ZXXRQAAIA3s9nc913hPhxYmm8sT548qSFDhujzzz93eZw5lr7lzdf/rtfi43TvA8P0zIt/lySdOvmrXnlpor7e+KXOpqWp5Y036dnJr6paDZ76h/Vual5TT9zbRc3rV1HF8mHq/8RbWrnhe8fxCuEheunxvurSup7CSgdr887DGj3tX/rx2EnHmC/eflztWtZ2Ou+/vtihe5+eX2SfA8XDQ7E36OQvxwvsv2XAYD38TLzOn8vUwhmT9e36L3Q27YzKR1dWr0FDdUv/wR6oFih6phvLUaNG6cyZM9q2bZs6duyoZcuW6ddff9VLL72kV1991R01wk327N6hpYvmq279ho59hmFo+JCBCigRoDcSlqpU6RAlvDlL9/fvpU827VDJkqU8WDGuRaWC7dpz6GctXLFNS159sMDxpa89pJzcPN0x6k2lZ17QyLs76bO5I9Ss30s6d+G/d0zmffi1XpzzieP1+aycIqkfxcvf3/tc+fn/DVCOHf6P4h4eqJu69pYkvfv3Sdq7fYtGTZmlCtEx2r11o96cMl5ly0eqVcdbPFU23IB1LF0zvY7lunXr9Nprr+n666+Xn5+fqlatqrvvvlvTpk1TfHy8O2qEG2RmZmjs8Pv14iuzFRr238Xuj/x0WN/t+FaTps5Qo6YtVKNWHU16eYYyz2Xq02X/8mDFuFat/nq/nn/jE3287rsCx2pVqaBWjatr5OQl2rH/mH44mqrH4z9QqWC7+se2cBp7/kK2fj191rGlZ1woqo+AYiQsPEJly1VwbImb1ioqppoatGwtSTr43Q517H2HGl7fRhUqxajb7XerWp36+nHf939xZuDaYLqxzMzMVIUKFSRJ4eHhOnny4u2oRo0aaefOndZWB7d5YfwT6tC5u9q06+S0Pzs7S5Jktwc59vn7+yswIEA7vt1SpDUC9sCLN1UuZOc69uXnG8rOyVWbpjWdxg7o0VLJ617Wjn9PUPwTf1PpkvYirRXFT05OtjZ++qE63zrQkTDVa3aDtm9crdO/npBhGNrz7df65ehPatqGh2CvNZfmWLpr81Wmb4XXrVtXBw8eVLVq1dS0aVO9+eabqlatmubOnauKFSu6o0ZY7NPl/9L+Pbv178+/KnCsRq26iq5cRdOnTNLz015XcMlSSnjzdZ1M/VUnf03xQLUozg4eSdHRX07rxRF99NhL7yvzfLYev6eTKpYPU1S5MMe4JZ9t15FfTuvXU+lqUCtaL4zorUZ1KqnXo7M9WD2udd+uW6XMs+nq1Ke/Y98DT7+oN54fpwe6tZB/iRKy2fw0fNIrqt+8lQcrBYrOFc2xPHHihCRp0qRJ6t69u9577z0FBgYqISHB6vpgsRM/H9eUieM0b8kK2YOCChwPCAjQ6+8s1rNjHlWrepXl7++v1jd3VLtO3TxQLYq73Nx83Tn2Hc2ZdJdObPq7cnPztO6bg1q1eZ/TuPnL/pum7//xhA4fS9WWxU+p6XWVtfs/BR+0AKywdtn7an5TR4VXiHLs+3TxPB36foeemZmg8tGVtX/Htv+fY1lBTW5s58FqYTXWsXTNdGN51113OX7drFkzHTlyRP/5z39UpUoVlStXztS54uPj9dFHH+k///mPgoOD1aZNG02dOlV169Y1WxYKad/3u3T61End1r2tY19eXp4St23We/Pf1PdHz6hhk2ZavnabzqanKSc7W+Hlyqt/j/Zq2KS5BytHcbXrQLJuHPiyQksHKTCghE6dydCmf47Vjv3H/vQ92Tm5qlWlAo0l3CL1l+P6/puv9OT0dxz7si6c13uvv6ynXpunlu26SJKq1amvpIP79PGCuTSWKBaueB3LS0qWLKnmza+s4di4caOGDx+u66+/Xrm5uZowYYK6deum/fv3q1Qpnj52hxtv7qAV67912vfMqEdUo1YdPfDYaPn7+zv2h4RevNV45KfD2vvdTo18cmKR1gr8r0sP49SsUl7N61fR8298ctmx9WtWVGBACZ04lVZU5aGYWffxEoWFl1PLm7s49uXl5io3N0c2P+fHF/z8/JWfn1/UJcLNWMfStUI1lqNHjy70CadPn17osatWrXJ6PX/+fFWoUEE7duxQu3b8y84dSpcOUZ3rGjjtCy5ZSmXKhjv2r1r5kcpGlFN0pRgdOrBPkyeOU+dbeqtthy6uTglclVLBgaoZU97xulqlCDWuU0ln0s8pOeWM+nVpppNnMpSc8psa1o7WK+Nu18oN3+vLbf+RJFWvXE4De7TUF5v369SZDNWrGaWXn+inXQeStXX3T576WLiG5efna93HH6hD7zvkX+K/f42WLB2iBi1ba8H0F2W3B6l8xcrat2OrNnzybw0ZO8mDFcMdWG7ItUI1lrt27SrUya72B5GWdjFdCA8Pd3k8KytLWVlZjtfp6elXdT24lvpril6Oe1qnT6aqfIUo9b1jkB594mlPl4VrVPP6VbX6nccdr6eNvU2StHDFNj00aZGiyodq6ph+qhARopRT6Xrvk28U/9Z//1Gak5OrjjfU1fA7O6p0yUAdT/ldqzbv1eQ3P1d+vlHknwfXvu+3bdLJEz+r860DCxwbM3WOFs2cotfGP6aM9N9VvmIlDXrsKXW/414PVAoUPZthGF7xJ69hGOrbt6/OnDmjr74q+LSyJMXFxen5558vsD/x0AmVDgl1d4mAaU1jn/R0CcBlvb9ggqdLAFw6l3FWd91UV2lpaQoN9a6/39PT0xUWFqaHFn2rwJKl3XKN7HMZeuvuG7zy8/8V0+tYustjjz2m77//Xu+///5lx4wfP15paWmOLTk5uQgrBAAAwJ+56od3rDBixAitWLFCmzZtUuXKlS87zm63y25n0WMAAOBZzLF0zaONpWEYGjFihJYtW6YNGzaoevXqniwHAAAAV8GjjeXw4cO1ePFiffzxxwoJCVFKysVvdgkLC1NwcLAnSwMAALgsm03yY7mhAjw6x3LOnDlKS0tThw4dVLFiRcf2wQcfeLIsAAAAXIEraiwXLlyom266SdHR0Tp69KgkacaMGfr4449NnccwDJfbfffddyVlAQAAFAk/m3s3X2W6sZwzZ45Gjx6tHj166Pfff1deXp4kqUyZMpoxY4bV9QEAAMBHmG4sZ82apbffflsTJkxw+vq/li1bas+ePZYWBwAA4I0uPRXurs1XmW4sk5KS1KxZswL77Xa7MjMzLSkKAAAAvsd0Y1m9enXt3r27wP7PP/9c9evXt6ImAAAAr8YcS9dMLzc0btw4DR8+XBcuXJBhGPr222/1/vvvKz4+Xu+88447agQAAIAPMN1YDhkyRLm5uXryySd17tw5DRo0SJUqVdLMmTM1cOBAd9QIAADgVWw296036cNTLK9sgfQHH3xQDz74oE6dOqX8/HxVqFDB6roAAADgY67qm3fKlStnVR0AAAA+w89mk5+bokV3nbcomG4sq1ev/qePwf/0009XVRAAAAB8k+nGctSoUU6vc3JytGvXLq1atUrjxo2zqi4AAACv5Sf3fS+2R79v+yqZbiwff/xxl/v/8Y9/KDEx8aoLAgAAgG+yrCmOjY3Vhx9+aNXpAAAAvNalp8LdtfkqyxrLf//73woPD7fqdAAAAPAxpm+FN2vWzOnhHcMwlJKSopMnT+qNN96wtDgAAABv5Cc3PhUu340sTSeWt956q/r27evY+vXrp0mTJmnv3r166KGH3FEjAAAALmPTpk3q3bu3oqOjZbPZtHz5cqfjhmEoLi5O0dHRCg4OVocOHbRv3z6nMVlZWRoxYoTKlSunUqVKqU+fPjp+/LjpWkwllrm5uapWrZq6d++uqKgo0xcDAAC4FnjTN+9kZmaqSZMmGjJkiG677bYCx6dNm6bp06crISFBderU0UsvvaSuXbvq4MGDCgkJkXRx1Z+VK1dqyZIlioiI0JgxY9SrVy/t2LFD/v7+ha7FVGNZokQJPfroozpw4ICZtwEAAMBNYmNjFRsb6/KYYRiaMWOGJkyYoH79+kmSFixYoMjISC1evFgPP/yw0tLSNG/ePC1cuFBdunSRJC1atEgxMTFau3atunfvXuhaTN8Kb9WqlXbt2mX2bQAAANcMP5t7N0lKT0932rKyskzXmZSUpJSUFHXr1s2xz263q3379tqyZYskaceOHcrJyXEaEx0drYYNGzrGFJbph3eGDRumMWPG6Pjx42rRooVKlSrldLxx48ZmTwkAAIA/iImJcXo9adIkxcXFmTpHSkqKJCkyMtJpf2RkpI4ePeoYExgYqLJlyxYYc+n9hVXoxvL+++/XjBkzNGDAAEnSyJEjHcdsNpsMw5DNZlNeXp6pAgAAAHyNzea+7/S+dNrk5GSFhoY69tvt9qs4p3Otl/q2P1OYMX9U6MZywYIFevnll5WUlGTqAgAAADAvNDTUqbG8Epcetk5JSVHFihUd+1NTUx0pZlRUlLKzs3XmzBmn1DI1NVVt2rQxdb1Cz7E0DEOSVLVq1T/dAAAArnW+8s071atXV1RUlNasWePYl52drY0bNzqaxhYtWiggIMBpzIkTJ7R3717TjaWpOZZm41AAAAC4V0ZGhg4fPux4nZSUpN27dys8PFxVqlTRqFGjNGXKFNWuXVu1a9fWlClTVLJkSQ0aNEiSFBYWpqFDh2rMmDGKiIhQeHi4xo4dq0aNGjmeEi8sU41lnTp1/rK5/O2330wVAAAA4Gv+9+ltd5zbjMTERHXs2NHxevTo0ZKkwYMHKyEhQU8++aTOnz+vYcOG6cyZM2rVqpVWr17tWMNSkl577TWVKFFC/fv31/nz59W5c2clJCSYWsNSMtlYPv/88woLCzN1AQAAALhPhw4dHFMWXbHZbIqLi/vTJ8qDgoI0a9YszZo166pqMdVYDhw4UBUqVLiqCwIAAPg62///565z+6pCP7zD/EoAAAD8mUInln8WsQIAABQn3jTH0psUurHMz893Zx0AAADwcaa/0hEAAKC4I7F0rdBzLAEAAIA/Q2IJAABgks1mc9uDzb78wDSJJQAAACxBYgkAAGAScyxdI7EEAACAJUgsAQAATLLZLm7uOrevIrEEAACAJUgsAQAATPKz2eTnpmjRXectCiSWAAAAsASJJQAAgEk8Fe4aiSUAAAAsQWIJAABglhufCheJJQAAAIo7EksAAACT/GSTn5uiRXedtyiQWAIAAMASJJYAAAAm8c07rpFYAgAAwBIklgAAACaxjqVrJJYAAACwBIklAACASXxXuGsklgAAALAEiSUAAIBJPBXuGoklAAAALEFiCQAAYJKf3DjH0oe/eYfGEgAAwCRuhbvGrXAAAABYgsQSAADAJD+5L53z5dTPl2sHAACAFyGxBAAAMMlms8nmpsmQ7jpvUSCxBAAAgCVILAEAAEyy/f/mrnP7KhJLAAAAWILEEgAAwCQ/mxsXSGeOJQAAAIo7EksAAIAr4Lu5ovuQWAIAAMASJJYAAAAm8V3hrpFYAgAAwBIklgAAACbxzTuukVgCAADAEiSWAAAAJvnJfemcL6d+vlw7AAAAvAiNJQAAgEmX5li6azMjNzdXzz77rKpXr67g4GDVqFFDL7zwgvLz8x1jDMNQXFycoqOjFRwcrA4dOmjfvn1W/1hoLAEAAHzZ1KlTNXfuXM2ePVsHDhzQtGnT9Pe//12zZs1yjJk2bZqmT5+u2bNna/v27YqKilLXrl119uxZS2uhsQQAADDJ5ubNjK1bt6pv377q2bOnqlWrpttvv13dunVTYmKipItp5YwZMzRhwgT169dPDRs21IIFC3Tu3DktXrz4Kn4KBdFYAgAA+LC2bdvqyy+/1KFDhyRJ3333nTZv3qwePXpIkpKSkpSSkqJu3bo53mO329W+fXtt2bLF0lp4KhwAAMCkoljHMj093Wm/3W6X3W4vMP6pp55SWlqarrvuOvn7+ysvL0+TJ0/WnXfeKUlKSUmRJEVGRjq9LzIyUkePHrW09muisYyJKKnQ0JKeLgMooMmAOzxdAnBZM9cneboEwKXcC5meLsErxMTEOL2eNGmS4uLiCoz74IMPtGjRIi1evFgNGjTQ7t27NWrUKEVHR2vw4MGOcX9shA3DsLw5viYaSwAAgKJUFOtYJicnKzQ01LHfVVopSePGjdPTTz+tgQMHSpIaNWqko0ePKj4+XoMHD1ZUVJSki8llxYoVHe9LTU0tkGJaVTsAAAC8SGhoqNN2ucby3Llz8vNzbun8/f0dyw1Vr15dUVFRWrNmjeN4dna2Nm7cqDZt2lhaM4klAACASd70XeG9e/fW5MmTVaVKFTVo0EC7du3S9OnTdf/99zvON2rUKE2ZMkW1a9dW7dq1NWXKFJUsWVKDBg2ytHYaSwAAAB82a9YsTZw4UcOGDVNqaqqio6P18MMP67nnnnOMefLJJ3X+/HkNGzZMZ86cUatWrbR69WqFhIRYWovNMAzD0jMWofT0dIWFhenX02lOcxAAb9HhlY2eLgG4rODgAE+XALiUeyFTm5/uprQ07/v7/VLv8d7Xh1SytLVN2SXnMs7qrpvqeOXn/yvMsQQAAIAluBUOAABgks12cXPXuX0ViSUAAAAsQWIJAABgkp9s8jP9rd6FP7evIrEEAACAJUgsAQAATGKOpWsklgAAALAEiSUAAIBJtv//z13n9lUklgAAALAEiSUAAIBJzLF0jcQSAAAAliCxBAAAMMnmxnUsmWMJAACAYo/EEgAAwCTmWLpGYgkAAABLkFgCAACYRGLpGoklAAAALEFiCQAAYBLfvOMaiSUAAAAsQWIJAABgkp/t4uauc/sqEksAAABYgsQSAADAJOZYukZiCQAAAEuQWAIAAJjEOpaukVgCAADAEiSWAAAAJtnkvrmQPhxYklgCAADAGiSWAAAAJrGOpWsklgAAALAEiSUAAIBJrGPpGoklAAAALEFiCQAAYBLrWLpGYgkAAABLkFgCAACYZJP71pv04cCSxBIAAADWILEEAAAwyU82+blpMqSfD2eWNJYAAAAmcSvcNW6FAwAAwBIklgAAAGYRWbpEYgkAAABLkFgCAACYxFc6ukZiCQAAAEuQWAIAAJjlxq909OHAksQSAAAA1iCxBAAAMImHwl0jsQQAAIAlSCwBAADMIrJ0icQSAADAx/3888+6++67FRERoZIlS6pp06basWOH47hhGIqLi1N0dLSCg4PVoUMH7du3z/I6aCwBAABMsrn5PzPOnDmjm266SQEBAfr888+1f/9+vfrqqypTpoxjzLRp0zR9+nTNnj1b27dvV1RUlLp27aqzZ89a+nPhVjgAAIAPmzp1qmJiYjR//nzHvmrVqjl+bRiGZsyYoQkTJqhfv36SpAULFigyMlKLFy/Www8/bFktJJYAAAAm2Wzu3cxYsWKFWrZsqTvuuEMVKlRQs2bN9PbbbzuOJyUlKSUlRd26dXPss9vtat++vbZs2WLVj0QSjSUAAIBXSk9Pd9qysrJcjvvpp580Z84c1a5dW1988YUeeeQRjRw5Uv/85z8lSSkpKZKkyMhIp/dFRkY6jlmFxhIAAMAkm5s3SYqJiVFYWJhji4+Pd1lLfn6+mjdvrilTpqhZs2Z6+OGH9eCDD2rOnDnONf8hCjUMo8C+q8UcSwAAAC+UnJys0NBQx2u73e5yXMWKFVW/fn2nffXq1dOHH34oSYqKipJ0MbmsWLGiY0xqamqBFPNqkVgCAACYVQSRZWhoqNN2ucbypptu0sGDB532HTp0SFWrVpUkVa9eXVFRUVqzZo3jeHZ2tjZu3Kg2bdpc5Q/CGYklAACAD3viiSfUpk0bTZkyRf3799e3336rt956S2+99Zaki7fAR40apSlTpqh27dqqXbu2pkyZopIlS2rQoEGW1kJjCQAAYNKVrDdp5txmXH/99Vq2bJnGjx+vF154QdWrV9eMGTN01113OcY8+eSTOn/+vIYNG6YzZ86oVatWWr16tUJCQiytncYSAADAx/Xq1Uu9evW67HGbzaa4uDjFxcW5tQ4aSwAAAJOuZL1JM+f2VTy8AwAAAEuQWAIAAJj0v+tNuuPcvorEEgAAAJYgsQQAADCLyNIlEksAAABYgsQSAADAJG9ax9KbkFgCAADAEiSWAAAAJrGOpWsklgAAALAEiSUAAIBJPBTuGo1lMfP3qfFavuwjHTr4HwUHB6tV6zaaPGWq6tStK0nKyclR3HPP6ovPP1NS0k8KDQtTp05d9OKUlxUdHe3h6nEtahoTprtbxahuZGmVD7HryQ/3atMPpx3HH2hbVV3qVVBkiF05+fk6mJKhuRuTtO/EWUlSxTC7lj16o8tzP7Nsn9YdPFUknwPXpsbRoRrQIlp1KpRWudKBenblf/T1T785jg9uFaNOdSJUPsSu3DxDh1IzNG/LMR34NcMxplfDSHWuW061y5dSKXsJ9ZrzjTKz8zzxcQC341Z4MfPVpo165NHh2rh5mz75fI3ycnPVq0c3ZWZmSpLOnTun3bt26ukJE7X1251asvQj/fDDId3xtz4erhzXquAAf/3wa4ZeXXPY5fFjv53Xq6t/0F3zEvXwot06kXZBMwc0VpngAEnSr+lZ6jFri9P21ldHdC47T1v/pwEArkRQgJ9+PJWp1zf85PL48d/Pa+aGJA1dtFsj/7VHKelZmva3+goL/m9uYy/hp2+P/q73En8uqrJRFGxu3nwUiWUxs+LTVU6v33xnvqpEV9CunTvU9uZ2CgsL06er1jiNmT5jlm5uc4OOHTumKlWqFGW5KAa2/vTbnzaAq/enOr2e8eWP6tOkompVKKXEo78r35B+y8xxGtO+ToTWHkjV+Zx8t9SM4uPbo7/r26O/X/b4l39IxN/46oh6NoxUzXKltDM5TZL04e4TkqQmlULdVifgLUgsi7n0tIt/8JUtG375MelpstlsKlOmTBFVBbhWws+mW5tW1NkLufohNcPlmLqRpVU3MkQrv08p4upQ3JXws6lXw0hlZOXq8MlMT5cDN7O5+T9fRWJZjBmGoafGjVabm9qqQcOGLsdcuHBBE595WgMGDlJoKP/ahmfcVDNcL/atr6AAP53KyNbIJd8r7Xyuy7F9mkQp6VSm9vycXsRVori6sXpZPXdLHdkD/HQ6M1tjl+1X+gXXvz+Ba51HE8s5c+aocePGCg0NVWhoqFq3bq3PP//ckyUVK0+MfEx79nyvBYved3k8JydH99w1UPn5+Zo5+40irg74rx3Hfte97ybqwYW7tO2n3zT51noqWzKgwDh7CT91qx9JWokitTs5TQ8s/k6PLd2j7Ud/16TYOo45wLh2XVrH0l2br/JoY1m5cmW9/PLLSkxMVGJiojp16qS+fftq3759niyrWHji8RH65JMV+mLNelWuXLnA8ZycHN11Z38dTUrSJ6vWkFbCoy7k5Ov47xe075ezmvL5IeXlG+rdOKrAuI51yykowE+f7fnVA1WiuLqQm69f0i7oQEqG/r72R+UZhno0qODpsgCP8Oit8N69ezu9njx5subMmaNt27apQYMGHqrq2mYYhp54fIRWfLxMq9duULXq1QuMudRU/nj4B61as14REREeqBT4EzabAksU/HdxnyYV9dUPp/X7+RwXbwKKhk1SgD+PMFzrWMfSNa+ZY5mXl6d//etfyszMVOvWrT1dzjVr1Ijh+mDJYv3ro49VOiREKSkXbxmGhYUpODhYubm5GjTgdu3atVMfLf9EeXl5jjHh4eEKDAz0ZPm4BgUH+Kly2WDH6+gyQapdoZTSL+Qq7XyO7mtdVV8dPqXTGdkKCw7Qbc2jVSHEri//c9LpPJXLBKlpTJhGL91T1B8B17CgAD9VCgtyvK4YZlfNciV1NitX6edzdfcNlfX1T7/pt8wchQaVUN/GUSpf2q6NP/z3afGyJQMUXjJAlcpcPE+NciV1LjtPqWezdTaLuZi4tni8sdyzZ49at26tCxcuqHTp0lq2bJnq16/vcmxWVpaysrIcr9PTmZxv1ltvzpEkdevcwXn/O/N1z+D79PPx4/pk5QpJUquWTZ3GfLF2vdq1d34fcLXqVQzRG4OaOl6P6lxLkvTpnhRNXXVI1SKC1aNRA5UJDlDa+RwdSDmrRxbtVtKpc07n6dW4ok6ezdI3SWeKsnxc4+pWKK0Zt//34cbh7S7e5Vm1P1XT1/2omLLBer5nXYUFBSj9Qq4O/pqhkf/eqyO/nXe8p0+jKN13Y4zj9et3NJIkvbz6B31xwPkfSPAhRJYu2QzDMDxZQHZ2to4dO6bff/9dH374od555x1t3LjRZXMZFxen559/vsD+X0+nMQcQXqnDKxs9XQJwWcE8YAIvlXshU5uf7qa0NO/7+z09PV1hYWH69uAvKh3intoyzqbrhrrRXvn5/4rHJ4EEBgaqVq1aatmypeLj49WkSRPNnDnT5djx48crLS3NsSUnJxdxtQAAAKxjeTkevxX+R4ZhON3u/l92u112u72IKwIAAEBheLSxfOaZZxQbG6uYmBidPXtWS5Ys0YYNG7Rq1aq/fjMAAICHuHO9SV9ex9KjjeWvv/6qe+65RydOnFBYWJgaN26sVatWqWvXrp4sCwAAAFfAo43lvHnzPHl5AACAK8JD4a55/OEdAAAAXBu87uEdAAAAr0dk6RKJJQAAACxBYgkAAGCSO9eb9OV1LEksAQAAYAkSSwAAALPcuI6lDweWJJYAAACwBoklAACASTwU7hqJJQAAACxBYgkAAGAWkaVLJJYAAACwBIklAACASaxj6RqJJQAAACxBYgkAAGCSzY3rWLptfcwiQGIJAAAAS5BYAgAAmMRD4a7RWAIAAJhFZ+kSt8IBAABgCRJLAAAAk1huyDUSSwAAAFiCxBIAAMAkm9y43JB7TlskSCwBAACuEfHx8bLZbBo1apRjn2EYiouLU3R0tIKDg9WhQwft27fPLdensQQAADDJ5ubtSmzfvl1vvfWWGjdu7LR/2rRpmj59umbPnq3t27crKipKXbt21dmzZ6/wSpdHYwkAAODjMjIydNddd+ntt99W2bJlHfsNw9CMGTM0YcIE9evXTw0bNtSCBQt07tw5LV682PI6aCwBAABMuvSVju7aJCk9Pd1py8rKumw9w4cPV8+ePdWlSxen/UlJSUpJSVG3bt0c++x2u9q3b68tW7ZY/nOhsQQAAPBCMTExCgsLc2zx8fEuxy1ZskQ7d+50eTwlJUWSFBkZ6bQ/MjLSccxKPBUOAABgmvu/eic5OVmhoaGOvXa7vcDI5ORkPf7441q9erWCgoIuf8Y/PMJuGEaBfVagsQQAAPBCoaGhTo2lKzt27FBqaqpatGjh2JeXl6dNmzZp9uzZOnjwoKSLyWXFihUdY1JTUwukmFbgVjgAAIBJRTHHsjA6d+6sPXv2aPfu3Y6tZcuWuuuuu7R7927VqFFDUVFRWrNmjeM92dnZ2rhxo9q0aWP5z4XEEgAAwEeFhISoYcOGTvtKlSqliIgIx/5Ro0ZpypQpql27tmrXrq0pU6aoZMmSGjRokOX10FgCAACY5P4ZltZ58skndf78eQ0bNkxnzpxRq1attHr1aoWEhFh8JRpLAACAa8qGDRucXttsNsXFxSkuLs7t16axBAAAMMnsXEiz5/ZVPLwDAAAAS5BYAgAAmGT7///cdW5fRWIJAAAAS5BYAgAAmOVLj4UXIRJLAAAAWILEEgAAwCQCS9dILAEAAGAJEksAAACTWMfSNRJLAAAAWILEEgAAwCTWsXSNxBIAAACWILEEAAAwi8fCXSKxBAAAgCVILAEAAEwisHSNxBIAAACWILEEAAAwiXUsXSOxBAAAgCVILAEAAExz3zqWvjzLksQSAAAAliCxBAAAMIk5lq6RWAIAAMASNJYAAACwBI0lAAAALMEcSwAAAJOYY+kaiSUAAAAsQWIJAABgks2N61i6b31M9yOxBAAAgCVILAEAAExijqVrJJYAAACwBIklAACASTa57xu9fTiwJLEEAACANUgsAQAAzCKydInEEgAAAJYgsQQAADCJdSxdI7EEAACAJUgsAQAATGIdS9dILAEAAGAJEksAAACTeCjcNRJLAAAAWILEEgAAwCwiS5dILAEAAGAJEksAAACTWMfSNRJLAAAAWILEEgAAwCTWsXTNpxtLwzAkSWfT0z1cCeBa7oVMT5cAXFauLcDTJQAuXfqz89Lf894o3Y29hzvP7W4+3ViePXtWklSreoyHKwEAAFY7e/aswsLCPF2Gk8DAQEVFRam2m3uPqKgoBQYGuvUa7mAzvPmfA38hPz9fv/zyi0JCQmTz5dzYS6SnpysmJkbJyckKDQ31dDmAE35/wpvx+9NahmHo7Nmzio6Olp+f9z0OcuHCBWVnZ7v1GoGBgQoKCnLrNdzBpxNLPz8/Va5c2dNlXHNCQ0P5gxFei9+f8Gb8/rSOtyWV/ysoKMgnm76i4H3/DAAAAIBPorEEAACAJWgs4WC32zVp0iTZ7XZPlwIUwO9PeDN+fwIX+fTDOwAAAPAeJJYAAACwBI0lAAAALEFjCQAAAEvQWAIAAMASNJYAfALPGQKA9/Ppb97B1cvLy5O/v7+nywBcyszMVH5+vgzD4NtM4HV+++03paamyt/fX1WrVvXJ73UGrEZiWYwdOnRIM2bM0IkTJzxdClDA/v371a9fP7Vv31716tXTe++9J4nkEt5h79696tKli/r3769GjRpp2rRpysvL83RZgMeRWBZThw8fVuvWrXXmzBmdPn1ao0ePVrly5TxdFiDpYlPZrl073Xvvvbr++uuVmJioIUOGqEGDBmratKmny0Mxt3//fnXo0EFDhgzRkCFD9Pnnn2vcuHEaPHiwYmJiPF0e4FEskF4MZWZmauTIkcrPz1fLli01YsQIjR07Vk8++STNJTzut99+05133qnrrrtOM2fOdOzv1KmTGjVqpJkzZ8owDNlsNg9WieLq1KlTuu2229SsWTPNmDFD0sUUvUePHnruuecUHBysiIgIGkwUWySWxZCfn59atGihiIgIDRgwQOXLl9fAgQMlieYSHpeTk6Pff/9dt99+uyQpPz9ffn5+qlGjhk6fPi1JNJXwGJvNpltuucXx+1OSXnrpJX3xxRdKSUnRqVOn1KBBAz377LNq27atBysFPIPGshgKDg7W4MGDVapUKUlS//79ZRiG7rzzThmGoaeffloRERHKz8/X0aNHVb16dQ9XjOIkMjJSixYtUu3atSVdfMDMz89PlSpVUlJSktPYjIwMlS5d2hNlopiKiIjQY489ppCQEEnSkiVLNGnSJL3//vvq2rWr9u7dq3HjxunLL7+ksUSxRGNZTF1qKi/9pT1gwAAZhqFBgwbJZrNp1KhReuWVV3T06FEtXLhQJUuW9HDFKE4uNZX5+fkKCAiQdPH36q+//uoYEx8fL7vdrpEjR6pECf4oQ9G51FRKUuvWrZWYmKjmzZtLktq1a6fIyEjt2LHDU+UBHsWfxsWcv7+/DMNQfn6+Bg4cKJvNpnvuuUcrVqzQjz/+qO3bt9NUwmP8/Pwc8yltNptjaaznnntOL730knbt2kVTCY+qWrWqqlatKuniXMvs7GyVLl1aDRs29HBlgGew3BAcf2kbhqEBAwbo5ptv1smTJ7Vz506ewIXHXXq+0N/fXzExMXrllVc0bdo0JSYmqkmTJh6uDvgvm82myZMn6+uvv9Ydd9zh6XIAj+Cf+pB08Q/EvLw8jRs3TuvXr9fu3bvVqFEjT5cFyM/v4r9/AwIC9Pbbbys0NFSbN2923HoEvMG///1vbdiwQUuWLNGaNWsc0zmA4obEEk4aNGignTt3qnHjxp4uBXDSvXt3SdKWLVvUsmVLD1cDOKtXr55OnjypTZs2qVmzZp4uB/AY1rGEE9YHhDfLzMx0PHgGeJucnBzHw2ZAcUVjCQAAAEtwKxwAAACWoLEEAACAJWgsAQAAYAkaSwAAAFiCxhIAAACWoLEEAACAJWgsAVgmLi7O6WtA77vvPt16661FXseRI0dks9m0e/fuy46pVq2aZsyYUehzJiQkqEyZMlddm81m0/Lly6/6PADgjWgsgWvcfffd5/g++ICAANWoUUNjx45VZmam2689c+ZMJSQkFGpsYZpBAIB347vCgWLglltu0fz585WTk6OvvvpKDzzwgDIzMzVnzpwCY6389pCwsDBLzgMA8A0klkAxYLfbFRUVpZiYGA0aNEh33XWX43bspdvX7777rmrUqCG73S7DMJSWlqaHHnpIFSpUUGhoqDp16qTvvvvO6bwvv/yyIiMjFRISoqFDh+rChQtOx/94Kzw/P19Tp05VrVq1ZLfbVaVKFU2ePFmSVL16dUlSs2bNZLPZ1KFDB8f75s+fr3r16ikoKEjXXXed3njjDafrfPvtt2rWrJmCgoLUsmVL7dq1y/TPaPr06WrUqJFKlSqlmJgYDRs2TBkZGQXGLV++XHXq1FFQUJC6du2q5ORkp+MrV65UixYtFBQUpBo1auj5559Xbm6u6XoAwBfRWALFUHBwsHJychyvDx8+rKVLl+rDDz903Iru2bOnUlJS9Nlnn2nHjh1q3ry5OnfurN9++02StHTpUk2aNEmTJ09WYmKiKlasWKDh+6Px48dr6tSpmjhxovbv36/FixcrMjJS0sXmUJLWrl2rEydO6KOPPpIkvf3225owYYImT56sAwcOaMqUKZo4caIWLFgg6eL3h/fq1Ut169bVjh07FBcXp7Fjx5r+mfj5+en111/X3r17tWDBAq1bt05PPvmk05hz585p8uTJWrBggb7++mulp6dr4MCBjuNffPGF7r77bo0cOVL79+/Xm2++qYSEBEfzDADXPAPANW3w4MFG3759Ha+/+eYbIyIiwujfv79hGIYxadIkIyAgwEhNTXWM+fLLL43Q0FDjwoULTueqWbOm8eabbxqGYRitW7c2HnnkEafjrVq1Mpo0aeLy2unp6Ybdbjfefvttl3UmJSUZkoxdu3Y57Y+JiTEWL17stO/FF180WrdubRiGYbz55ptGeHi4kZmZ6Tg+Z84cl+f6X1WrVjVee+21yx5funSpERER4Xg9f/58Q5Kxbds2x74DBw4YkoxvvvnGMAzDuPnmm40pU6Y4nWfhwoVGxYoVHa8lGcuWLbvsdQHAlzHHEigGPvnkE5UuXVq5ubnKyclR3759NWvWLMfxqlWrqnz58o7XO3bsUEZGhiIiIpzOc/78ef3444+SpAMHDuiRRx5xOt66dWutX7/eZQ0HDhxQVlaWOnfuXOi6T548qeTkZA0dOlQPPvigY39ubq5j/uaBAwfUpEkTlSxZ0qkOs9avX68pU6Zo//79Sk9PV25uri5cuKDMzEyVKlVKklSiRAm1bNnS8Z7rrrtOZcqU0YEDB3TDDTdox44d2r59u1NCmZeXpwsXLujcuXNONQLAtYjGEigGOnbsqDlz5iggIEDR0dEFHs651Dhdkp+fr4oVK2rDhg0FznWlS+4EBwebfk9+fr6ki7fDW7Vq5XTM399fkmQYxhXV87+OHj2qHj166JFHHtGLL76o8PBwbd68WUOHDnWaMiBdXC7ojy7ty8/P1/PPP69+/foVGBMUFHTVdQKAt6OxBIqBUqVKqVatWoUe37x5c6WkpKhEiRKqVq2ayzH16tXTtm3bdO+99zr2bdu27bLnrF27toKDg/Xll1/qgQceKHA8MDBQ0sWE75LIyEhVqlRJP/30k+666y6X561fv74WLlyo8+fPO5rXP6vDlcTEROXm5urVV1+Vn9/FqedLly4tMC43N1eJiYm64YYbJEkHDx7U77//ruuuu07SxZ/bwYMHTf2sAeBaQmMJoIAuXbqodevWuvXWWzV16lTVrVtXv/zyiz777DPdeuutatmypR5//HENHjxYLVu2VNu2bfXee+9p3759qlGjhstzBgUF6amnntKTTz6pwMBA3XTTTTp58qT27dunoUOHqkKFCgoODtaqVatUuXJlBQUFKSwsTHFxcRo5cqRCQ0MVGxurrKwsJSYm6syZMxo9erQGDRqkCRMmaOjQoXr22Wd15MgRvfLKK6Y+b82aNZWbm6tZs2apd+/e+vrrrzV37twC4wICAjRixAi9/vrrCggI0GOPPaYbb7zR0Wg+99xz6tWrl2JiYnTHHXfIz89P33//vfbs2aOXXnrJ/P8IAPAxPBUOoACbzabPPvtM7dq10/333686depo4MCBOnLkiOMp7gEDBui5557TU089pRYtWujo0aN69NFH//S8EydO1JgxY/Tcc8+pXr16GjBggFJTUyVdnL/4+uuv680331R0dLT69u0rSXrggQf0zjvvKCEhQY0aNVL79u2VkJDgWJ6odOnSWrlypfbv369mzZppwoQJmjp1qqnP27RpU02fPl1Tp05Vw4YN9d577yk+Pr7AuJIlS+qpp57SoEGD1Lp1awUHB2vJkiWO4927d9cnn3yiNWvW6Prrr9eNN96o6dOnq2rVqqbqAQBfZTOsmKAEAACAYo/EEgAAAJagsQQAAIAlaCwBAABgCRpLAAAAWILGEgAAAJagsQQAAIAlaCwBAABgCRpLAAAAWILGEgAAAJagsQQAAIAlaCwBAABgCRpLAAAAWOL/ALZngd13pzlBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Define tick marks for classes\n",
    "categories = np.unique(Y_test)  # Ensure categories are derived from the data\n",
    "tick_marks = np.arange(len(categories))\n",
    "plt.xticks(tick_marks, categories, rotation=45)\n",
    "plt.yticks(tick_marks, categories)\n",
    "\n",
    "# Add numerical values to the confusion matrix\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c516cc8b-f795-4f44-9ed0-653ae831f2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConfusion matrix visualizes the performance of a Neural Networks_classifier model \\nacross three classes: 1, 2, and 3. The rows represent the true labels, \\nwhile the columns represent the predicted labels. Diagonal values \\n(e.g., 31 for class 1, 197 for class 2, and 119 for class 3) \\nindicate correct predictions. Off-diagonal values represent \\nmisclassifications, such as 105 instances of class 1 being misclassified \\ns class 2 and 154 instances of class 3 being misclassified as class 2.\\nClass 2 has the highest correct predictions (197),\\nbut it also shows a substantial number of misclassifications into other classes. \\nOverall, the confusion matrix highlights that the model performs best for class 2\\nbut struggles with misclassifications, especially between class 1 and class 2 and between class 3 and class 2.\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Confusion matrix visualizes the performance of a Neural Networks_classifier model \n",
    "across three classes: 1, 2, and 3. The rows represent the true labels, \n",
    "while the columns represent the predicted labels. Diagonal values \n",
    "(e.g., 31 for class 1, 197 for class 2, and 119 for class 3) \n",
    "indicate correct predictions. Off-diagonal values represent \n",
    "misclassifications, such as 105 instances of class 1 being misclassified \n",
    "s class 2 and 154 instances of class 3 being misclassified as class 2.\n",
    "Class 2 has the highest correct predictions (197),\n",
    "but it also shows a substantial number of misclassifications into other classes. \n",
    "Overall, the confusion matrix highlights that the model performs best for class 2\n",
    "but struggles with misclassifications, especially between class 1 and class 2 and between class 3 and class 2.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93706e46-e28a-41f4-9d0e-bc1f64a3ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score (Weighted): 0.47447492332334257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "pre_score = precision_score(Y_test, Y_pred, average='weighted')\n",
    "print(\"Precision Score (Weighted):\", pre_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76b9e84d-0b73-4762-959f-e08e5136ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfb6d6dd-cb7d-4b19-85e7-cc8b7b2d9a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of f1_score: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of f1_score:\", type(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa473a60-23ec-4511-aa6d-847b028e31a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31690140845070425, 0.5263157894736842, 0.4897196261682243]\n"
     ]
    }
   ],
   "source": [
    "accuracy_result = accuracy_score(Y_test, Y_pred)\n",
    "precision_result = precision_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(f1_score)\n",
    "recall_result1 = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1_result = f1Score(Y_test, Y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f80faff-5f82-47b8-ab83-6859235730b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31690140845070425, 0.5263157894736842, 0.4897196261682243]\n"
     ]
    }
   ],
   "source": [
    "accuracy_result = accuracy_score(Y_test, Y_pred)\n",
    "precision_result = precision_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "print(f1_score)\n",
    "recall_result1 = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1_result = f1Score(Y_test, Y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "219469af-c27c-4d87-8e61-9050c3380b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = {\\n    \"Test_Size\": test_size1,\\n    \"random_state\": random_state1,\\n    \"accuracy\": accuracy_result\\n}'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data = {\n",
    "    \"Test_Size\": test_size1,\n",
    "    \"random_state\": random_state1,\n",
    "    \"accuracy\": accuracy_result\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "aa0dfa4a-45b8-4cb3-a225-981744bb448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(Y_test, Y_pred, output_dict=True)\n",
    "\n",
    "column_order = [\n",
    "    \"Test_Size\", \"random_state\", \"accuracy\",\n",
    "    \"1_precision\", \"1_recall\", \"1_f1-score\", \"1_support\",\n",
    "    \"2_precision\", \"2_recall\", \"2_f1-score\", \"2_support\",\n",
    "    \"3_precision\", \"3_recall\", \"3_f1-score\", \"3_support\",\n",
    "    \"macro avg_precision\", \"macro avg_recall\", \"macro avg_f1-score\",\n",
    "    \"weighted avg_precision\", \"weighted avg_recall\", \"weighted avg_f1-score\",\n",
    "]\n",
    "\n",
    "# Flatten metrics to match the column order\n",
    "flattened_metrics = {}\n",
    "flattened_metrics[\"Test_Size\"] = test_size1  # Ensure this is defined\n",
    "flattened_metrics[\"random_state\"] = random_state1  # Ensure this is defined\n",
    "flattened_metrics[\"accuracy\"] = report.get(\"accuracy\", None)\n",
    "\n",
    "# Loop through labels and metrics to extract values\n",
    "for label in [\"1\", \"2\", \"3\", \"macro avg\", \"weighted avg\"]:\n",
    "    for metric in [\"precision\", \"recall\", \"f1-score\", \"support\"]:\n",
    "        column_name = f\"{label}_{metric.replace(' ', '_')}\"\n",
    "        flattened_metrics[column_name] = report.get(label, {}).get(metric, None)\n",
    "\n",
    "# Convert the flattened dictionary into a DataFrame\n",
    "final_report_df = pd.DataFrame([flattened_metrics])\n",
    "\n",
    "# Ensure the columns are in the correct order\n",
    "for col in column_order:\n",
    "    if col not in final_report_df.columns:\n",
    "        final_report_df[col] = None  # Add missing columns with NaN\n",
    "\n",
    "final_report_df = final_report_df[column_order]  # Reorder columns\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"Neural_Networks_Classifier_Resultsaabbbbbbbbbbbbbbbbbbb.csv\"\n",
    "\n",
    "if os.path.isfile(csv_file):\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "    if not existing_df.equals(final_report_df):\n",
    "        final_report_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "else:\n",
    "    final_report_df.to_csv(csv_file, mode='w', header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbaa15a-d5b2-4670-88cf-ae7f6ee62b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bb625-12ad-43cc-83f2-060ddfc4b2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
